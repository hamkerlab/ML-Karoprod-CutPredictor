{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cut Predictor # Tensorflow and optuna-based utility to learn to predict deviations from 1D position (or angles) based on a set of process parameters. Installation # Dependencies: numpy pandas matplotlib ipywidgets tensorflow >=2.6 optuna pip install git+https://github.com/hamkerlab/ML-Karoprod-CutPredictor.git@master","title":"Installation"},{"location":"#cut-predictor","text":"Tensorflow and optuna-based utility to learn to predict deviations from 1D position (or angles) based on a set of process parameters.","title":"Cut Predictor"},{"location":"#installation","text":"Dependencies: numpy pandas matplotlib ipywidgets tensorflow >=2.6 optuna pip install git+https://github.com/hamkerlab/ML-Karoprod-CutPredictor.git@master","title":"Installation"},{"location":"CutPredictor/","text":"CutPredictor # cut_predictor.CutPredictor # Bases: object Regression method to predict 1D cuts from process parameters. Source code in cut_predictor/Regressor.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 class CutPredictor ( object ): \"\"\" Regression method to predict 1D cuts from process parameters. \"\"\" def __init__ ( self , data , process_parameters , position , output , categorical = [], angle = False ): \"\"\" Loads a pandas Dataframe containing the data and preprocesses it. :param data: pandas.Dataframe object. :param process_parameters: list of process parameters. The names must match the columns of the csv file. :param position: position variable. The name must match one column of the csv file. :param output: output variable to be predicted. The name must match one column of the csv file. :param angle: if the position parameter is an angle, its sine and cosine are used as inputs instead. \"\"\" self . model = None # Attributes names self . process_parameters = process_parameters self . position_attribute = position self . output_attribute = output self . categorical_attributes = categorical self . angle_input = angle # Extract relevant data self . features = self . process_parameters + [ self . position_attribute ] self . df_X = data [ self . features ] self . df_Y = data [ self . output_attribute ] # Min/Max/Mean/Std values self . min_values = {} self . max_values = {} self . mean_values = {} self . std_values = {} mins = self . df_X . min ( axis = 0 ) maxs = self . df_X . max ( axis = 0 ) means = self . df_X . mean ( axis = 0 ) stds = self . df_X . std ( axis = 0 ) for attr in self . features : self . min_values [ attr ] = mins [ attr ] self . max_values [ attr ] = maxs [ attr ] self . mean_values [ attr ] = means [ attr ] self . std_values [ attr ] = stds [ attr ] self . min_values [ self . output_attribute ] = self . df_Y . min ( axis = 0 ) self . max_values [ self . output_attribute ] = self . df_Y . max ( axis = 0 ) self . mean_values [ self . output_attribute ] = self . df_Y . mean ( axis = 0 ) self . std_values [ self . output_attribute ] = self . df_Y . std ( axis = 0 ) # Categorical attributes self . categorical_values = {} for attr in self . categorical_attributes : self . categorical_values [ attr ] = sorted ( self . df_X [ attr ] . unique ()) # Get numpy arrays self . X = self . df_X . to_numpy () self . target = self . df_Y . to_numpy () # Normalizing input data self . _input_normalization () self . input_shape = ( self . X . shape [ 1 ], ) def _input_normalization ( self ): N , _ = self . X . shape X = np . empty (( N , 0 )) for idx , attr in enumerate ( self . features ): if attr == self . position_attribute : if not self . angle_input : values = (( self . X [:, idx ] - self . mean_values [ attr ] ) / self . std_values [ attr ]) . reshape (( N , 1 )) X = np . concatenate ( ( X , values ), axis = 1 ) else : angle = self . X [:, idx ] X = np . concatenate (( X , np . cos ( angle ) . reshape (( N , 1 )) ), axis = 1 ) X = np . concatenate (( X , np . sin ( angle ) . reshape (( N , 1 )) ), axis = 1 ) elif attr in self . categorical_attributes : X = np . concatenate (( X , one_hot ( self . X [:, idx ], self . categorical_values [ attr ]) ), axis = 1 ) else : X = np . concatenate ( ( X , (( self . X [:, idx ] - self . mean_values [ attr ] ) / self . std_values [ attr ]) . reshape (( N , 1 )) ), axis = 1 ) self . X = X # Normalize output self . target = ( self . target - self . min_values [ self . output_attribute ]) / ( self . max_values [ self . output_attribute ] - self . min_values [ self . output_attribute ]) # Rescales the output def _rescale_output ( self , y ): return self . min_values [ self . output_attribute ] + ( self . max_values [ self . output_attribute ] - self . min_values [ self . output_attribute ]) * y def data_summary ( self ): \"\"\" Displays a summary of the loaded data. \"\"\" print ( \"Data summary \\n \" + \"-\" * 60 + \" \\n \" ) print ( \"Process parameters:\" ) for param in self . process_parameters : if param in self . categorical_attributes : print ( \" \\t -\" , param , \": categorical \" + str ( self . categorical_values [ param ]) ) else : print ( \" \\t -\" , param , \": numerical [\" , self . min_values [ param ], \" ... \" , self . max_values [ param ], \"]\" ) if self . angle_input : print ( \"Angle variable:\" ) else : print ( \"Position variable:\" ) print ( \" \\t -\" , self . position_attribute , \": numerical,\" , \"[\" , self . min_values [ self . position_attribute ], \"/\" , self . max_values [ self . position_attribute ], \"]\" ) print ( \"Output variable:\" ) print ( \" \\t -\" , self . output_attribute , \": numerical,\" , \"[\" , self . min_values [ self . output_attribute ], \"/\" , self . max_values [ self . output_attribute ], \"]\" ) print ( \" \\n Inputs \\n \" + \"-\" * 60 + \" \\n \" ) print ( self . X . shape ) print ( \" \\n Outputs \\n \" + \"-\" * 60 + \" \\n \" ) print ( self . target . shape ) def _create_model ( self , config ): # Clear the session tf . keras . backend . clear_session () # Create the model model = tf . keras . Sequential () model . add ( tf . keras . layers . Input ( self . input_shape )) # Add layers for n in config [ 'layers' ]: model . add ( tf . keras . layers . Dense ( n , activation = 'relu' )) if config [ 'dropout' ] > 0.0 : model . add ( tf . keras . layers . Dropout ( config [ 'dropout' ])) # Output layer model . add ( tf . keras . layers . Dense ( 1 )) # Compile model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = config [ 'learning_rate' ]), loss = tf . keras . losses . MeanSquaredError () ) return model def trial ( self , trial ): # Sample hyperparameters layers = [] nb_layers = trial . suggest_int ( 'nb_layers' , self . range_layers [ 0 ], self . range_layers [ 1 ]) for n in range ( nb_layers ): num_hidden = trial . suggest_int ( f 'n_units_l { n } ' , self . range_neurons [ 0 ], self . range_neurons [ 1 ], step = self . range_neurons [ 2 ]) layers . append ( num_hidden ) learning_rate = trial . suggest_loguniform ( 'learning_rate' , self . range_learning_rate [ 0 ], self . range_learning_rate [ 1 ]) dropout = trial . suggest_discrete_uniform ( 'dropout' , self . range_dropout [ 0 ], self . range_dropout [ 1 ], self . range_dropout [ 2 ]) config = { 'batch_size' : self . batch_size , 'max_epochs' : self . max_epochs , 'layers' : layers , 'dropout' : dropout , 'learning_rate' : learning_rate } # Create the model model = self . _create_model ( config ) # Train history = model . fit ( self . X , self . target , validation_split = 0.1 , epochs = self . max_epochs , batch_size = self . batch_size , verbose = 0 ) # Check performance val_mse = history . history [ 'val_loss' ][ - 1 ] # Save the best network if val_mse < self . best_mse : self . best_mse = val_mse model . save ( self . save_path ) self . best_history = history self . best_config = config return val_mse def autotune ( self , trials , save_path = 'best_model' , batch_size = 4096 , max_epochs = 20 , layers = [ 3 , 6 ], neurons = [ 64 , 512 , 32 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-6 , 1e-3 ] ): \"\"\" Searches for the optimal network configuration for the data. :param trials: number of trials to perform. :param save_path: path to save the best model (default: 'best_model'). :param batch_size: batch size to be used (default: 4096). :param max_epochs: maximum number of epochs for the training of a single network (default: 20) :param layers: range for the number of layers (default: [3, 6]). :param neurons: range (and optionally step) for the number of neurons per layer (default: [64, 512, 32]). If only two values are provided, the step is assumed to be 1. :param dropout: range and step for the dropout level (default: [0.0, 0.5, 0.1]). :param learning_rate: range for the learning rate (default: [1e-6, 1e-3]). The values will be sampled log-uniformly. \"\"\" # Save arguments self . save_path = save_path self . batch_size = batch_size self . max_epochs = max_epochs self . range_layers = layers self . range_neurons = neurons if len ( self . range_neurons ) == 2 : self . range_neurons . append ( 1 ) self . range_dropout = dropout self . range_learning_rate = learning_rate # Keep the best network only self . best_mse = 10000000.0 self . best_history = None # Start the study self . study = optuna . create_study ( direction = 'minimize' ) self . study . optimize ( self . trial , n_trials = trials ) if self . best_history is None : print ( \"Error: could not find a correct configuration\" ) return None # Reload the best model self . model = tf . keras . models . load_model ( self . save_path ) return self . best_config def custom_model ( self , save_path = 'best_model' , config = { 'batch_size' : 4096 , 'max_epochs' : 30 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 }, verbose = False , ): \"\"\" Creates and trains a single model instead of the autotuning procedure. The dictionary describing the structure of the network must contain the following fields: * batch_size: batch size to be used (default: 4096). * max_epochs: maximum number of epochs for the training of a single network (default: 20) * layers: list of the number of neurons in each layer (default: [128, 128, 128, 128, 128]). * dropout: dropout level (default: 0.0). * learning_rate: learning rate (default: [0.005]). :param save_path: path to save the best model (default: 'best_model'). :param config: dictionary containing the description of the model. :param verbose: whether training details should be printed. \"\"\" # Save arguments self . save_path = save_path self . best_config = config self . batch_size = config [ 'batch_size' ] # Create the model self . model = self . _create_model ( self . best_config ) if verbose : self . model . summary () # Train history = self . model . fit ( self . X , self . target , validation_split = 0.1 , epochs = self . best_config [ 'max_epochs' ], batch_size = self . best_config [ 'batch_size' ], verbose = 1 if verbose else 0 ) # Check performance val_mse = history . history [ 'val_loss' ][ - 1 ] # Save the best network self . best_mse = val_mse self . model . save ( self . save_path ) self . best_history = history print ( \"Validation mse:\" , self . best_mse ) def training_summary ( self ): \"\"\" Creates various plots related to the best network. Can only be called after ``autotune()`` or ``custom_model``. You need to finally call `plt.show()` if you are in a script. \"\"\" # Training performance plt . figure () plt . plot ( self . best_history . history [ 'loss' ][:], label = \"training\" ) plt . plot ( self . best_history . history [ 'val_loss' ][:], label = \"validation\" ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( \"mse\" ) plt . title ( \"Training performance\" ) plt . legend () plt . savefig ( self . save_path + \"/training.png\" ) y = self . model . predict ( self . X , batch_size = self . batch_size ) plt . figure () plt . scatter ( self . _rescale_output ( self . target ), self . _rescale_output ( y ), s = 1 ) plt . xlabel ( \"Ground truth\" ) plt . ylabel ( \"Prediction\" ) plt . title ( \"Ground truth vs. prediction\" ) plt . savefig ( self . save_path + \"/prediction.png\" ) plt . figure () plt . subplot ( 121 ) plt . hist ( self . _rescale_output ( self . target )) plt . xlabel ( \"Ground truth\" ) plt . subplot ( 122 ) plt . hist ( self . _rescale_output ( y )) plt . xlabel ( \"Prediction\" ) plt . title ( \"Statistics\" ) plt . savefig ( self . save_path + \"/distribution.png\" ) def load ( self , load_path = 'best_model' , batch_size = 4096 ): \"\"\" Load a pretrained network from a saved folder. The only parameter not saved by default is the batch size. :param load_path: path to the directory where the best network was saved (default: 'best_model') :param batch_size: batch size to be used (default: 4096). \"\"\" self . batch_size = batch_size self . save_path = load_path self . model = tf . keras . models . load_model ( self . save_path ) def predict ( self , process_parameters , nb_points ): \"\"\" Predicts the output variable for a given number of input positions (uniformly distributed between the min/max values used for training). :param process_parameters: dictionary containing the value of all process parameters. :param nb_points: number of input positions to be used for the prediction. \"\"\" if self . model is None : print ( \"Error: no model has been trained yet.\" ) return position = np . linspace ( self . min_values [ self . position_attribute ], self . max_values [ self . position_attribute ], nb_points ) X = np . empty (( nb_points , 0 )) for idx , attr in enumerate ( self . features ): if attr == self . position_attribute : if not self . angle_input : values = ( position . reshape (( nb_points , 1 )) - self . mean_values [ attr ] ) / self . std_values [ attr ] X = np . concatenate (( X , values ), axis = 1 ) else : X = np . concatenate ( ( X , np . cos ( position ) . reshape (( nb_points , 1 )) ), axis = 1 ) X = np . concatenate ( ( X , np . sin ( position ) . reshape (( nb_points , 1 )) ), axis = 1 ) elif attr in self . categorical_attributes : code = one_hot ([ process_parameters [ attr ]], self . categorical_values [ attr ]) code = np . repeat ( code , nb_points , axis = 0 ) X = np . concatenate (( X , code ), axis = 1 ) else : val = (( process_parameters [ attr ] - self . mean_values [ attr ] ) / self . std_values [ attr ]) * np . ones (( nb_points , 1 )) X = np . concatenate (( X , val ), axis = 1 ) y = self . model . predict ( X , batch_size = self . batch_size ) y = self . _rescale_output ( y ) return position , y def compare ( self , start , stop ): \"\"\" Compares the prediction and the ground truth for the data points if indices comprised between start and stop. Creates a matplotlib figure. :param start: start index (included). :param stop: stop index (excluded). \"\"\" if self . model is None : print ( \"Error: no model has been trained yet.\" ) return X = self . X [ start : stop ] t = self . _rescale_output ( self . target [ start : stop ]) position = self . mean_values [ self . position_attribute ] + self . std_values [ self . position_attribute ] * X [:, - 1 ] # position is the last index y = self . model . predict ( X , batch_size = self . batch_size ) y = self . _rescale_output ( y ) plt . figure () plt . plot ( position , y , label = \"prediction\" ) plt . plot ( position , t , label = \"data\" ) plt . xlabel ( self . position_attribute ) plt . ylabel ( self . output_attribute ) plt . ylim (( self . min_values [ self . output_attribute ], self . max_values [ self . output_attribute ])) plt . legend () def interactive ( self ): \"\"\" Method to interactively vary the process parameters and predict the corresponding cut. Only work in a Jupyter notebook. ```python %matplotlib inline plt.rcParams['figure.dpi'] = 150 reg.interactive() ``` \"\"\" values = {} for attr in self . features : if attr == self . position_attribute : continue elif attr in self . categorical_attributes : values [ attr ] = widgets . Dropdown ( options = self . categorical_values [ attr ], value = self . categorical_values [ attr ][ 0 ], ) else : values [ attr ] = widgets . FloatSlider ( value = self . mean_values [ attr ], min = self . min_values [ attr ], max = self . max_values [ attr ], step = ( self . max_values [ attr ] - self . min_values [ attr ]) / 100. , ) display ( widgets . interactive ( self . _visualize , ** values ) ) def _visualize ( self , ** values ): x , y = self . predict ( values , 100 ) plt . figure () plt . plot ( x , y ) plt . xlabel ( self . position_attribute ) plt . ylabel ( self . output_attribute ) plt . xlim (( self . min_values [ self . position_attribute ], self . max_values [ self . position_attribute ])) plt . ylim (( self . min_values [ self . output_attribute ], self . max_values [ self . output_attribute ])) plt . show () __init__ ( data , process_parameters , position , output , categorical = [], angle = False ) # Loads a pandas Dataframe containing the data and preprocesses it. Parameters: Name Type Description Default data pandas.Dataframe object. required process_parameters list of process parameters. The names must match the columns of the csv file. required position position variable. The name must match one column of the csv file. required output output variable to be predicted. The name must match one column of the csv file. required angle if the position parameter is an angle, its sine and cosine are used as inputs instead. False Source code in cut_predictor/Regressor.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def __init__ ( self , data , process_parameters , position , output , categorical = [], angle = False ): \"\"\" Loads a pandas Dataframe containing the data and preprocesses it. :param data: pandas.Dataframe object. :param process_parameters: list of process parameters. The names must match the columns of the csv file. :param position: position variable. The name must match one column of the csv file. :param output: output variable to be predicted. The name must match one column of the csv file. :param angle: if the position parameter is an angle, its sine and cosine are used as inputs instead. \"\"\" self . model = None # Attributes names self . process_parameters = process_parameters self . position_attribute = position self . output_attribute = output self . categorical_attributes = categorical self . angle_input = angle # Extract relevant data self . features = self . process_parameters + [ self . position_attribute ] self . df_X = data [ self . features ] self . df_Y = data [ self . output_attribute ] # Min/Max/Mean/Std values self . min_values = {} self . max_values = {} self . mean_values = {} self . std_values = {} mins = self . df_X . min ( axis = 0 ) maxs = self . df_X . max ( axis = 0 ) means = self . df_X . mean ( axis = 0 ) stds = self . df_X . std ( axis = 0 ) for attr in self . features : self . min_values [ attr ] = mins [ attr ] self . max_values [ attr ] = maxs [ attr ] self . mean_values [ attr ] = means [ attr ] self . std_values [ attr ] = stds [ attr ] self . min_values [ self . output_attribute ] = self . df_Y . min ( axis = 0 ) self . max_values [ self . output_attribute ] = self . df_Y . max ( axis = 0 ) self . mean_values [ self . output_attribute ] = self . df_Y . mean ( axis = 0 ) self . std_values [ self . output_attribute ] = self . df_Y . std ( axis = 0 ) # Categorical attributes self . categorical_values = {} for attr in self . categorical_attributes : self . categorical_values [ attr ] = sorted ( self . df_X [ attr ] . unique ()) # Get numpy arrays self . X = self . df_X . to_numpy () self . target = self . df_Y . to_numpy () # Normalizing input data self . _input_normalization () self . input_shape = ( self . X . shape [ 1 ], ) autotune ( trials , save_path = 'best_model' , batch_size = 4096 , max_epochs = 20 , layers = [ 3 , 6 ], neurons = [ 64 , 512 , 32 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-06 , 0.001 ]) # Searches for the optimal network configuration for the data. Parameters: Name Type Description Default trials number of trials to perform. required save_path path to save the best model (default: 'best_model'). 'best_model' batch_size batch size to be used (default: 4096). 4096 max_epochs maximum number of epochs for the training of a single network (default: 20) 20 layers range for the number of layers (default: [3, 6]). [3, 6] neurons range (and optionally step) for the number of neurons per layer (default: [64, 512, 32]). If only two values are provided, the step is assumed to be 1. [64, 512, 32] dropout range and step for the dropout level (default: [0.0, 0.5, 0.1]). [0.0, 0.5, 0.1] learning_rate range for the learning rate (default: [1e-6, 1e-3]). The values will be sampled log-uniformly. [1e-06, 0.001] Source code in cut_predictor/Regressor.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def autotune ( self , trials , save_path = 'best_model' , batch_size = 4096 , max_epochs = 20 , layers = [ 3 , 6 ], neurons = [ 64 , 512 , 32 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-6 , 1e-3 ] ): \"\"\" Searches for the optimal network configuration for the data. :param trials: number of trials to perform. :param save_path: path to save the best model (default: 'best_model'). :param batch_size: batch size to be used (default: 4096). :param max_epochs: maximum number of epochs for the training of a single network (default: 20) :param layers: range for the number of layers (default: [3, 6]). :param neurons: range (and optionally step) for the number of neurons per layer (default: [64, 512, 32]). If only two values are provided, the step is assumed to be 1. :param dropout: range and step for the dropout level (default: [0.0, 0.5, 0.1]). :param learning_rate: range for the learning rate (default: [1e-6, 1e-3]). The values will be sampled log-uniformly. \"\"\" # Save arguments self . save_path = save_path self . batch_size = batch_size self . max_epochs = max_epochs self . range_layers = layers self . range_neurons = neurons if len ( self . range_neurons ) == 2 : self . range_neurons . append ( 1 ) self . range_dropout = dropout self . range_learning_rate = learning_rate # Keep the best network only self . best_mse = 10000000.0 self . best_history = None # Start the study self . study = optuna . create_study ( direction = 'minimize' ) self . study . optimize ( self . trial , n_trials = trials ) if self . best_history is None : print ( \"Error: could not find a correct configuration\" ) return None # Reload the best model self . model = tf . keras . models . load_model ( self . save_path ) return self . best_config compare ( start , stop ) # Compares the prediction and the ground truth for the data points if indices comprised between start and stop. Creates a matplotlib figure. Parameters: Name Type Description Default start start index (included). required stop stop index (excluded). required Source code in cut_predictor/Regressor.py 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 def compare ( self , start , stop ): \"\"\" Compares the prediction and the ground truth for the data points if indices comprised between start and stop. Creates a matplotlib figure. :param start: start index (included). :param stop: stop index (excluded). \"\"\" if self . model is None : print ( \"Error: no model has been trained yet.\" ) return X = self . X [ start : stop ] t = self . _rescale_output ( self . target [ start : stop ]) position = self . mean_values [ self . position_attribute ] + self . std_values [ self . position_attribute ] * X [:, - 1 ] # position is the last index y = self . model . predict ( X , batch_size = self . batch_size ) y = self . _rescale_output ( y ) plt . figure () plt . plot ( position , y , label = \"prediction\" ) plt . plot ( position , t , label = \"data\" ) plt . xlabel ( self . position_attribute ) plt . ylabel ( self . output_attribute ) plt . ylim (( self . min_values [ self . output_attribute ], self . max_values [ self . output_attribute ])) plt . legend () custom_model ( save_path = 'best_model' , config = { 'batch_size' : 4096 , 'max_epochs' : 30 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 }, verbose = False ) # Creates and trains a single model instead of the autotuning procedure. The dictionary describing the structure of the network must contain the following fields: batch_size: batch size to be used (default: 4096). max_epochs: maximum number of epochs for the training of a single network (default: 20) layers: list of the number of neurons in each layer (default: [128, 128, 128, 128, 128]). dropout: dropout level (default: 0.0). learning_rate: learning rate (default: [0.005]). Parameters: Name Type Description Default save_path path to save the best model (default: 'best_model'). 'best_model' config dictionary containing the description of the model. {'batch_size': 4096, 'max_epochs': 30, 'layers': [128, 128, 128, 128, 128], 'dropout': 0.0, 'learning_rate': 0.005} verbose whether training details should be printed. False Source code in cut_predictor/Regressor.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def custom_model ( self , save_path = 'best_model' , config = { 'batch_size' : 4096 , 'max_epochs' : 30 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 }, verbose = False , ): \"\"\" Creates and trains a single model instead of the autotuning procedure. The dictionary describing the structure of the network must contain the following fields: * batch_size: batch size to be used (default: 4096). * max_epochs: maximum number of epochs for the training of a single network (default: 20) * layers: list of the number of neurons in each layer (default: [128, 128, 128, 128, 128]). * dropout: dropout level (default: 0.0). * learning_rate: learning rate (default: [0.005]). :param save_path: path to save the best model (default: 'best_model'). :param config: dictionary containing the description of the model. :param verbose: whether training details should be printed. \"\"\" # Save arguments self . save_path = save_path self . best_config = config self . batch_size = config [ 'batch_size' ] # Create the model self . model = self . _create_model ( self . best_config ) if verbose : self . model . summary () # Train history = self . model . fit ( self . X , self . target , validation_split = 0.1 , epochs = self . best_config [ 'max_epochs' ], batch_size = self . best_config [ 'batch_size' ], verbose = 1 if verbose else 0 ) # Check performance val_mse = history . history [ 'val_loss' ][ - 1 ] # Save the best network self . best_mse = val_mse self . model . save ( self . save_path ) self . best_history = history print ( \"Validation mse:\" , self . best_mse ) data_summary () # Displays a summary of the loaded data. Source code in cut_predictor/Regressor.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def data_summary ( self ): \"\"\" Displays a summary of the loaded data. \"\"\" print ( \"Data summary \\n \" + \"-\" * 60 + \" \\n \" ) print ( \"Process parameters:\" ) for param in self . process_parameters : if param in self . categorical_attributes : print ( \" \\t -\" , param , \": categorical \" + str ( self . categorical_values [ param ]) ) else : print ( \" \\t -\" , param , \": numerical [\" , self . min_values [ param ], \" ... \" , self . max_values [ param ], \"]\" ) if self . angle_input : print ( \"Angle variable:\" ) else : print ( \"Position variable:\" ) print ( \" \\t -\" , self . position_attribute , \": numerical,\" , \"[\" , self . min_values [ self . position_attribute ], \"/\" , self . max_values [ self . position_attribute ], \"]\" ) print ( \"Output variable:\" ) print ( \" \\t -\" , self . output_attribute , \": numerical,\" , \"[\" , self . min_values [ self . output_attribute ], \"/\" , self . max_values [ self . output_attribute ], \"]\" ) print ( \" \\n Inputs \\n \" + \"-\" * 60 + \" \\n \" ) print ( self . X . shape ) print ( \" \\n Outputs \\n \" + \"-\" * 60 + \" \\n \" ) print ( self . target . shape ) interactive () # Method to interactively vary the process parameters and predict the corresponding cut. Only work in a Jupyter notebook. % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive () Source code in cut_predictor/Regressor.py 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 def interactive ( self ): \"\"\" Method to interactively vary the process parameters and predict the corresponding cut. Only work in a Jupyter notebook. ```python %matplotlib inline plt.rcParams['figure.dpi'] = 150 reg.interactive() ``` \"\"\" values = {} for attr in self . features : if attr == self . position_attribute : continue elif attr in self . categorical_attributes : values [ attr ] = widgets . Dropdown ( options = self . categorical_values [ attr ], value = self . categorical_values [ attr ][ 0 ], ) else : values [ attr ] = widgets . FloatSlider ( value = self . mean_values [ attr ], min = self . min_values [ attr ], max = self . max_values [ attr ], step = ( self . max_values [ attr ] - self . min_values [ attr ]) / 100. , ) display ( widgets . interactive ( self . _visualize , ** values ) ) load ( load_path = 'best_model' , batch_size = 4096 ) # Load a pretrained network from a saved folder. The only parameter not saved by default is the batch size. Parameters: Name Type Description Default load_path path to the directory where the best network was saved (default: 'best_model') 'best_model' batch_size batch size to be used (default: 4096). 4096 Source code in cut_predictor/Regressor.py 377 378 379 380 381 382 383 384 385 386 387 388 def load ( self , load_path = 'best_model' , batch_size = 4096 ): \"\"\" Load a pretrained network from a saved folder. The only parameter not saved by default is the batch size. :param load_path: path to the directory where the best network was saved (default: 'best_model') :param batch_size: batch size to be used (default: 4096). \"\"\" self . batch_size = batch_size self . save_path = load_path self . model = tf . keras . models . load_model ( self . save_path ) predict ( process_parameters , nb_points ) # Predicts the output variable for a given number of input positions (uniformly distributed between the min/max values used for training). Parameters: Name Type Description Default process_parameters dictionary containing the value of all process parameters. required nb_points number of input positions to be used for the prediction. required Source code in cut_predictor/Regressor.py 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 def predict ( self , process_parameters , nb_points ): \"\"\" Predicts the output variable for a given number of input positions (uniformly distributed between the min/max values used for training). :param process_parameters: dictionary containing the value of all process parameters. :param nb_points: number of input positions to be used for the prediction. \"\"\" if self . model is None : print ( \"Error: no model has been trained yet.\" ) return position = np . linspace ( self . min_values [ self . position_attribute ], self . max_values [ self . position_attribute ], nb_points ) X = np . empty (( nb_points , 0 )) for idx , attr in enumerate ( self . features ): if attr == self . position_attribute : if not self . angle_input : values = ( position . reshape (( nb_points , 1 )) - self . mean_values [ attr ] ) / self . std_values [ attr ] X = np . concatenate (( X , values ), axis = 1 ) else : X = np . concatenate ( ( X , np . cos ( position ) . reshape (( nb_points , 1 )) ), axis = 1 ) X = np . concatenate ( ( X , np . sin ( position ) . reshape (( nb_points , 1 )) ), axis = 1 ) elif attr in self . categorical_attributes : code = one_hot ([ process_parameters [ attr ]], self . categorical_values [ attr ]) code = np . repeat ( code , nb_points , axis = 0 ) X = np . concatenate (( X , code ), axis = 1 ) else : val = (( process_parameters [ attr ] - self . mean_values [ attr ] ) / self . std_values [ attr ]) * np . ones (( nb_points , 1 )) X = np . concatenate (( X , val ), axis = 1 ) y = self . model . predict ( X , batch_size = self . batch_size ) y = self . _rescale_output ( y ) return position , y training_summary () # Creates various plots related to the best network. Can only be called after autotune() or custom_model . You need to finally call plt.show() if you are in a script. Source code in cut_predictor/Regressor.py 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 def training_summary ( self ): \"\"\" Creates various plots related to the best network. Can only be called after ``autotune()`` or ``custom_model``. You need to finally call `plt.show()` if you are in a script. \"\"\" # Training performance plt . figure () plt . plot ( self . best_history . history [ 'loss' ][:], label = \"training\" ) plt . plot ( self . best_history . history [ 'val_loss' ][:], label = \"validation\" ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( \"mse\" ) plt . title ( \"Training performance\" ) plt . legend () plt . savefig ( self . save_path + \"/training.png\" ) y = self . model . predict ( self . X , batch_size = self . batch_size ) plt . figure () plt . scatter ( self . _rescale_output ( self . target ), self . _rescale_output ( y ), s = 1 ) plt . xlabel ( \"Ground truth\" ) plt . ylabel ( \"Prediction\" ) plt . title ( \"Ground truth vs. prediction\" ) plt . savefig ( self . save_path + \"/prediction.png\" ) plt . figure () plt . subplot ( 121 ) plt . hist ( self . _rescale_output ( self . target )) plt . xlabel ( \"Ground truth\" ) plt . subplot ( 122 ) plt . hist ( self . _rescale_output ( y )) plt . xlabel ( \"Prediction\" ) plt . title ( \"Statistics\" ) plt . savefig ( self . save_path + \"/distribution.png\" )","title":"CutPredictor"},{"location":"CutPredictor/#cutpredictor","text":"","title":"CutPredictor"},{"location":"CutPredictor/#cut_predictor.CutPredictor","text":"Bases: object Regression method to predict 1D cuts from process parameters. Source code in cut_predictor/Regressor.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 class CutPredictor ( object ): \"\"\" Regression method to predict 1D cuts from process parameters. \"\"\" def __init__ ( self , data , process_parameters , position , output , categorical = [], angle = False ): \"\"\" Loads a pandas Dataframe containing the data and preprocesses it. :param data: pandas.Dataframe object. :param process_parameters: list of process parameters. The names must match the columns of the csv file. :param position: position variable. The name must match one column of the csv file. :param output: output variable to be predicted. The name must match one column of the csv file. :param angle: if the position parameter is an angle, its sine and cosine are used as inputs instead. \"\"\" self . model = None # Attributes names self . process_parameters = process_parameters self . position_attribute = position self . output_attribute = output self . categorical_attributes = categorical self . angle_input = angle # Extract relevant data self . features = self . process_parameters + [ self . position_attribute ] self . df_X = data [ self . features ] self . df_Y = data [ self . output_attribute ] # Min/Max/Mean/Std values self . min_values = {} self . max_values = {} self . mean_values = {} self . std_values = {} mins = self . df_X . min ( axis = 0 ) maxs = self . df_X . max ( axis = 0 ) means = self . df_X . mean ( axis = 0 ) stds = self . df_X . std ( axis = 0 ) for attr in self . features : self . min_values [ attr ] = mins [ attr ] self . max_values [ attr ] = maxs [ attr ] self . mean_values [ attr ] = means [ attr ] self . std_values [ attr ] = stds [ attr ] self . min_values [ self . output_attribute ] = self . df_Y . min ( axis = 0 ) self . max_values [ self . output_attribute ] = self . df_Y . max ( axis = 0 ) self . mean_values [ self . output_attribute ] = self . df_Y . mean ( axis = 0 ) self . std_values [ self . output_attribute ] = self . df_Y . std ( axis = 0 ) # Categorical attributes self . categorical_values = {} for attr in self . categorical_attributes : self . categorical_values [ attr ] = sorted ( self . df_X [ attr ] . unique ()) # Get numpy arrays self . X = self . df_X . to_numpy () self . target = self . df_Y . to_numpy () # Normalizing input data self . _input_normalization () self . input_shape = ( self . X . shape [ 1 ], ) def _input_normalization ( self ): N , _ = self . X . shape X = np . empty (( N , 0 )) for idx , attr in enumerate ( self . features ): if attr == self . position_attribute : if not self . angle_input : values = (( self . X [:, idx ] - self . mean_values [ attr ] ) / self . std_values [ attr ]) . reshape (( N , 1 )) X = np . concatenate ( ( X , values ), axis = 1 ) else : angle = self . X [:, idx ] X = np . concatenate (( X , np . cos ( angle ) . reshape (( N , 1 )) ), axis = 1 ) X = np . concatenate (( X , np . sin ( angle ) . reshape (( N , 1 )) ), axis = 1 ) elif attr in self . categorical_attributes : X = np . concatenate (( X , one_hot ( self . X [:, idx ], self . categorical_values [ attr ]) ), axis = 1 ) else : X = np . concatenate ( ( X , (( self . X [:, idx ] - self . mean_values [ attr ] ) / self . std_values [ attr ]) . reshape (( N , 1 )) ), axis = 1 ) self . X = X # Normalize output self . target = ( self . target - self . min_values [ self . output_attribute ]) / ( self . max_values [ self . output_attribute ] - self . min_values [ self . output_attribute ]) # Rescales the output def _rescale_output ( self , y ): return self . min_values [ self . output_attribute ] + ( self . max_values [ self . output_attribute ] - self . min_values [ self . output_attribute ]) * y def data_summary ( self ): \"\"\" Displays a summary of the loaded data. \"\"\" print ( \"Data summary \\n \" + \"-\" * 60 + \" \\n \" ) print ( \"Process parameters:\" ) for param in self . process_parameters : if param in self . categorical_attributes : print ( \" \\t -\" , param , \": categorical \" + str ( self . categorical_values [ param ]) ) else : print ( \" \\t -\" , param , \": numerical [\" , self . min_values [ param ], \" ... \" , self . max_values [ param ], \"]\" ) if self . angle_input : print ( \"Angle variable:\" ) else : print ( \"Position variable:\" ) print ( \" \\t -\" , self . position_attribute , \": numerical,\" , \"[\" , self . min_values [ self . position_attribute ], \"/\" , self . max_values [ self . position_attribute ], \"]\" ) print ( \"Output variable:\" ) print ( \" \\t -\" , self . output_attribute , \": numerical,\" , \"[\" , self . min_values [ self . output_attribute ], \"/\" , self . max_values [ self . output_attribute ], \"]\" ) print ( \" \\n Inputs \\n \" + \"-\" * 60 + \" \\n \" ) print ( self . X . shape ) print ( \" \\n Outputs \\n \" + \"-\" * 60 + \" \\n \" ) print ( self . target . shape ) def _create_model ( self , config ): # Clear the session tf . keras . backend . clear_session () # Create the model model = tf . keras . Sequential () model . add ( tf . keras . layers . Input ( self . input_shape )) # Add layers for n in config [ 'layers' ]: model . add ( tf . keras . layers . Dense ( n , activation = 'relu' )) if config [ 'dropout' ] > 0.0 : model . add ( tf . keras . layers . Dropout ( config [ 'dropout' ])) # Output layer model . add ( tf . keras . layers . Dense ( 1 )) # Compile model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = config [ 'learning_rate' ]), loss = tf . keras . losses . MeanSquaredError () ) return model def trial ( self , trial ): # Sample hyperparameters layers = [] nb_layers = trial . suggest_int ( 'nb_layers' , self . range_layers [ 0 ], self . range_layers [ 1 ]) for n in range ( nb_layers ): num_hidden = trial . suggest_int ( f 'n_units_l { n } ' , self . range_neurons [ 0 ], self . range_neurons [ 1 ], step = self . range_neurons [ 2 ]) layers . append ( num_hidden ) learning_rate = trial . suggest_loguniform ( 'learning_rate' , self . range_learning_rate [ 0 ], self . range_learning_rate [ 1 ]) dropout = trial . suggest_discrete_uniform ( 'dropout' , self . range_dropout [ 0 ], self . range_dropout [ 1 ], self . range_dropout [ 2 ]) config = { 'batch_size' : self . batch_size , 'max_epochs' : self . max_epochs , 'layers' : layers , 'dropout' : dropout , 'learning_rate' : learning_rate } # Create the model model = self . _create_model ( config ) # Train history = model . fit ( self . X , self . target , validation_split = 0.1 , epochs = self . max_epochs , batch_size = self . batch_size , verbose = 0 ) # Check performance val_mse = history . history [ 'val_loss' ][ - 1 ] # Save the best network if val_mse < self . best_mse : self . best_mse = val_mse model . save ( self . save_path ) self . best_history = history self . best_config = config return val_mse def autotune ( self , trials , save_path = 'best_model' , batch_size = 4096 , max_epochs = 20 , layers = [ 3 , 6 ], neurons = [ 64 , 512 , 32 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-6 , 1e-3 ] ): \"\"\" Searches for the optimal network configuration for the data. :param trials: number of trials to perform. :param save_path: path to save the best model (default: 'best_model'). :param batch_size: batch size to be used (default: 4096). :param max_epochs: maximum number of epochs for the training of a single network (default: 20) :param layers: range for the number of layers (default: [3, 6]). :param neurons: range (and optionally step) for the number of neurons per layer (default: [64, 512, 32]). If only two values are provided, the step is assumed to be 1. :param dropout: range and step for the dropout level (default: [0.0, 0.5, 0.1]). :param learning_rate: range for the learning rate (default: [1e-6, 1e-3]). The values will be sampled log-uniformly. \"\"\" # Save arguments self . save_path = save_path self . batch_size = batch_size self . max_epochs = max_epochs self . range_layers = layers self . range_neurons = neurons if len ( self . range_neurons ) == 2 : self . range_neurons . append ( 1 ) self . range_dropout = dropout self . range_learning_rate = learning_rate # Keep the best network only self . best_mse = 10000000.0 self . best_history = None # Start the study self . study = optuna . create_study ( direction = 'minimize' ) self . study . optimize ( self . trial , n_trials = trials ) if self . best_history is None : print ( \"Error: could not find a correct configuration\" ) return None # Reload the best model self . model = tf . keras . models . load_model ( self . save_path ) return self . best_config def custom_model ( self , save_path = 'best_model' , config = { 'batch_size' : 4096 , 'max_epochs' : 30 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 }, verbose = False , ): \"\"\" Creates and trains a single model instead of the autotuning procedure. The dictionary describing the structure of the network must contain the following fields: * batch_size: batch size to be used (default: 4096). * max_epochs: maximum number of epochs for the training of a single network (default: 20) * layers: list of the number of neurons in each layer (default: [128, 128, 128, 128, 128]). * dropout: dropout level (default: 0.0). * learning_rate: learning rate (default: [0.005]). :param save_path: path to save the best model (default: 'best_model'). :param config: dictionary containing the description of the model. :param verbose: whether training details should be printed. \"\"\" # Save arguments self . save_path = save_path self . best_config = config self . batch_size = config [ 'batch_size' ] # Create the model self . model = self . _create_model ( self . best_config ) if verbose : self . model . summary () # Train history = self . model . fit ( self . X , self . target , validation_split = 0.1 , epochs = self . best_config [ 'max_epochs' ], batch_size = self . best_config [ 'batch_size' ], verbose = 1 if verbose else 0 ) # Check performance val_mse = history . history [ 'val_loss' ][ - 1 ] # Save the best network self . best_mse = val_mse self . model . save ( self . save_path ) self . best_history = history print ( \"Validation mse:\" , self . best_mse ) def training_summary ( self ): \"\"\" Creates various plots related to the best network. Can only be called after ``autotune()`` or ``custom_model``. You need to finally call `plt.show()` if you are in a script. \"\"\" # Training performance plt . figure () plt . plot ( self . best_history . history [ 'loss' ][:], label = \"training\" ) plt . plot ( self . best_history . history [ 'val_loss' ][:], label = \"validation\" ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( \"mse\" ) plt . title ( \"Training performance\" ) plt . legend () plt . savefig ( self . save_path + \"/training.png\" ) y = self . model . predict ( self . X , batch_size = self . batch_size ) plt . figure () plt . scatter ( self . _rescale_output ( self . target ), self . _rescale_output ( y ), s = 1 ) plt . xlabel ( \"Ground truth\" ) plt . ylabel ( \"Prediction\" ) plt . title ( \"Ground truth vs. prediction\" ) plt . savefig ( self . save_path + \"/prediction.png\" ) plt . figure () plt . subplot ( 121 ) plt . hist ( self . _rescale_output ( self . target )) plt . xlabel ( \"Ground truth\" ) plt . subplot ( 122 ) plt . hist ( self . _rescale_output ( y )) plt . xlabel ( \"Prediction\" ) plt . title ( \"Statistics\" ) plt . savefig ( self . save_path + \"/distribution.png\" ) def load ( self , load_path = 'best_model' , batch_size = 4096 ): \"\"\" Load a pretrained network from a saved folder. The only parameter not saved by default is the batch size. :param load_path: path to the directory where the best network was saved (default: 'best_model') :param batch_size: batch size to be used (default: 4096). \"\"\" self . batch_size = batch_size self . save_path = load_path self . model = tf . keras . models . load_model ( self . save_path ) def predict ( self , process_parameters , nb_points ): \"\"\" Predicts the output variable for a given number of input positions (uniformly distributed between the min/max values used for training). :param process_parameters: dictionary containing the value of all process parameters. :param nb_points: number of input positions to be used for the prediction. \"\"\" if self . model is None : print ( \"Error: no model has been trained yet.\" ) return position = np . linspace ( self . min_values [ self . position_attribute ], self . max_values [ self . position_attribute ], nb_points ) X = np . empty (( nb_points , 0 )) for idx , attr in enumerate ( self . features ): if attr == self . position_attribute : if not self . angle_input : values = ( position . reshape (( nb_points , 1 )) - self . mean_values [ attr ] ) / self . std_values [ attr ] X = np . concatenate (( X , values ), axis = 1 ) else : X = np . concatenate ( ( X , np . cos ( position ) . reshape (( nb_points , 1 )) ), axis = 1 ) X = np . concatenate ( ( X , np . sin ( position ) . reshape (( nb_points , 1 )) ), axis = 1 ) elif attr in self . categorical_attributes : code = one_hot ([ process_parameters [ attr ]], self . categorical_values [ attr ]) code = np . repeat ( code , nb_points , axis = 0 ) X = np . concatenate (( X , code ), axis = 1 ) else : val = (( process_parameters [ attr ] - self . mean_values [ attr ] ) / self . std_values [ attr ]) * np . ones (( nb_points , 1 )) X = np . concatenate (( X , val ), axis = 1 ) y = self . model . predict ( X , batch_size = self . batch_size ) y = self . _rescale_output ( y ) return position , y def compare ( self , start , stop ): \"\"\" Compares the prediction and the ground truth for the data points if indices comprised between start and stop. Creates a matplotlib figure. :param start: start index (included). :param stop: stop index (excluded). \"\"\" if self . model is None : print ( \"Error: no model has been trained yet.\" ) return X = self . X [ start : stop ] t = self . _rescale_output ( self . target [ start : stop ]) position = self . mean_values [ self . position_attribute ] + self . std_values [ self . position_attribute ] * X [:, - 1 ] # position is the last index y = self . model . predict ( X , batch_size = self . batch_size ) y = self . _rescale_output ( y ) plt . figure () plt . plot ( position , y , label = \"prediction\" ) plt . plot ( position , t , label = \"data\" ) plt . xlabel ( self . position_attribute ) plt . ylabel ( self . output_attribute ) plt . ylim (( self . min_values [ self . output_attribute ], self . max_values [ self . output_attribute ])) plt . legend () def interactive ( self ): \"\"\" Method to interactively vary the process parameters and predict the corresponding cut. Only work in a Jupyter notebook. ```python %matplotlib inline plt.rcParams['figure.dpi'] = 150 reg.interactive() ``` \"\"\" values = {} for attr in self . features : if attr == self . position_attribute : continue elif attr in self . categorical_attributes : values [ attr ] = widgets . Dropdown ( options = self . categorical_values [ attr ], value = self . categorical_values [ attr ][ 0 ], ) else : values [ attr ] = widgets . FloatSlider ( value = self . mean_values [ attr ], min = self . min_values [ attr ], max = self . max_values [ attr ], step = ( self . max_values [ attr ] - self . min_values [ attr ]) / 100. , ) display ( widgets . interactive ( self . _visualize , ** values ) ) def _visualize ( self , ** values ): x , y = self . predict ( values , 100 ) plt . figure () plt . plot ( x , y ) plt . xlabel ( self . position_attribute ) plt . ylabel ( self . output_attribute ) plt . xlim (( self . min_values [ self . position_attribute ], self . max_values [ self . position_attribute ])) plt . ylim (( self . min_values [ self . output_attribute ], self . max_values [ self . output_attribute ])) plt . show ()","title":"CutPredictor"},{"location":"CutPredictor/#cut_predictor.Regressor.CutPredictor.__init__","text":"Loads a pandas Dataframe containing the data and preprocesses it. Parameters: Name Type Description Default data pandas.Dataframe object. required process_parameters list of process parameters. The names must match the columns of the csv file. required position position variable. The name must match one column of the csv file. required output output variable to be predicted. The name must match one column of the csv file. required angle if the position parameter is an angle, its sine and cosine are used as inputs instead. False Source code in cut_predictor/Regressor.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def __init__ ( self , data , process_parameters , position , output , categorical = [], angle = False ): \"\"\" Loads a pandas Dataframe containing the data and preprocesses it. :param data: pandas.Dataframe object. :param process_parameters: list of process parameters. The names must match the columns of the csv file. :param position: position variable. The name must match one column of the csv file. :param output: output variable to be predicted. The name must match one column of the csv file. :param angle: if the position parameter is an angle, its sine and cosine are used as inputs instead. \"\"\" self . model = None # Attributes names self . process_parameters = process_parameters self . position_attribute = position self . output_attribute = output self . categorical_attributes = categorical self . angle_input = angle # Extract relevant data self . features = self . process_parameters + [ self . position_attribute ] self . df_X = data [ self . features ] self . df_Y = data [ self . output_attribute ] # Min/Max/Mean/Std values self . min_values = {} self . max_values = {} self . mean_values = {} self . std_values = {} mins = self . df_X . min ( axis = 0 ) maxs = self . df_X . max ( axis = 0 ) means = self . df_X . mean ( axis = 0 ) stds = self . df_X . std ( axis = 0 ) for attr in self . features : self . min_values [ attr ] = mins [ attr ] self . max_values [ attr ] = maxs [ attr ] self . mean_values [ attr ] = means [ attr ] self . std_values [ attr ] = stds [ attr ] self . min_values [ self . output_attribute ] = self . df_Y . min ( axis = 0 ) self . max_values [ self . output_attribute ] = self . df_Y . max ( axis = 0 ) self . mean_values [ self . output_attribute ] = self . df_Y . mean ( axis = 0 ) self . std_values [ self . output_attribute ] = self . df_Y . std ( axis = 0 ) # Categorical attributes self . categorical_values = {} for attr in self . categorical_attributes : self . categorical_values [ attr ] = sorted ( self . df_X [ attr ] . unique ()) # Get numpy arrays self . X = self . df_X . to_numpy () self . target = self . df_Y . to_numpy () # Normalizing input data self . _input_normalization () self . input_shape = ( self . X . shape [ 1 ], )","title":"__init__()"},{"location":"CutPredictor/#cut_predictor.Regressor.CutPredictor.autotune","text":"Searches for the optimal network configuration for the data. Parameters: Name Type Description Default trials number of trials to perform. required save_path path to save the best model (default: 'best_model'). 'best_model' batch_size batch size to be used (default: 4096). 4096 max_epochs maximum number of epochs for the training of a single network (default: 20) 20 layers range for the number of layers (default: [3, 6]). [3, 6] neurons range (and optionally step) for the number of neurons per layer (default: [64, 512, 32]). If only two values are provided, the step is assumed to be 1. [64, 512, 32] dropout range and step for the dropout level (default: [0.0, 0.5, 0.1]). [0.0, 0.5, 0.1] learning_rate range for the learning rate (default: [1e-6, 1e-3]). The values will be sampled log-uniformly. [1e-06, 0.001] Source code in cut_predictor/Regressor.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def autotune ( self , trials , save_path = 'best_model' , batch_size = 4096 , max_epochs = 20 , layers = [ 3 , 6 ], neurons = [ 64 , 512 , 32 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-6 , 1e-3 ] ): \"\"\" Searches for the optimal network configuration for the data. :param trials: number of trials to perform. :param save_path: path to save the best model (default: 'best_model'). :param batch_size: batch size to be used (default: 4096). :param max_epochs: maximum number of epochs for the training of a single network (default: 20) :param layers: range for the number of layers (default: [3, 6]). :param neurons: range (and optionally step) for the number of neurons per layer (default: [64, 512, 32]). If only two values are provided, the step is assumed to be 1. :param dropout: range and step for the dropout level (default: [0.0, 0.5, 0.1]). :param learning_rate: range for the learning rate (default: [1e-6, 1e-3]). The values will be sampled log-uniformly. \"\"\" # Save arguments self . save_path = save_path self . batch_size = batch_size self . max_epochs = max_epochs self . range_layers = layers self . range_neurons = neurons if len ( self . range_neurons ) == 2 : self . range_neurons . append ( 1 ) self . range_dropout = dropout self . range_learning_rate = learning_rate # Keep the best network only self . best_mse = 10000000.0 self . best_history = None # Start the study self . study = optuna . create_study ( direction = 'minimize' ) self . study . optimize ( self . trial , n_trials = trials ) if self . best_history is None : print ( \"Error: could not find a correct configuration\" ) return None # Reload the best model self . model = tf . keras . models . load_model ( self . save_path ) return self . best_config","title":"autotune()"},{"location":"CutPredictor/#cut_predictor.Regressor.CutPredictor.compare","text":"Compares the prediction and the ground truth for the data points if indices comprised between start and stop. Creates a matplotlib figure. Parameters: Name Type Description Default start start index (included). required stop stop index (excluded). required Source code in cut_predictor/Regressor.py 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 def compare ( self , start , stop ): \"\"\" Compares the prediction and the ground truth for the data points if indices comprised between start and stop. Creates a matplotlib figure. :param start: start index (included). :param stop: stop index (excluded). \"\"\" if self . model is None : print ( \"Error: no model has been trained yet.\" ) return X = self . X [ start : stop ] t = self . _rescale_output ( self . target [ start : stop ]) position = self . mean_values [ self . position_attribute ] + self . std_values [ self . position_attribute ] * X [:, - 1 ] # position is the last index y = self . model . predict ( X , batch_size = self . batch_size ) y = self . _rescale_output ( y ) plt . figure () plt . plot ( position , y , label = \"prediction\" ) plt . plot ( position , t , label = \"data\" ) plt . xlabel ( self . position_attribute ) plt . ylabel ( self . output_attribute ) plt . ylim (( self . min_values [ self . output_attribute ], self . max_values [ self . output_attribute ])) plt . legend ()","title":"compare()"},{"location":"CutPredictor/#cut_predictor.Regressor.CutPredictor.custom_model","text":"Creates and trains a single model instead of the autotuning procedure. The dictionary describing the structure of the network must contain the following fields: batch_size: batch size to be used (default: 4096). max_epochs: maximum number of epochs for the training of a single network (default: 20) layers: list of the number of neurons in each layer (default: [128, 128, 128, 128, 128]). dropout: dropout level (default: 0.0). learning_rate: learning rate (default: [0.005]). Parameters: Name Type Description Default save_path path to save the best model (default: 'best_model'). 'best_model' config dictionary containing the description of the model. {'batch_size': 4096, 'max_epochs': 30, 'layers': [128, 128, 128, 128, 128], 'dropout': 0.0, 'learning_rate': 0.005} verbose whether training details should be printed. False Source code in cut_predictor/Regressor.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def custom_model ( self , save_path = 'best_model' , config = { 'batch_size' : 4096 , 'max_epochs' : 30 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 }, verbose = False , ): \"\"\" Creates and trains a single model instead of the autotuning procedure. The dictionary describing the structure of the network must contain the following fields: * batch_size: batch size to be used (default: 4096). * max_epochs: maximum number of epochs for the training of a single network (default: 20) * layers: list of the number of neurons in each layer (default: [128, 128, 128, 128, 128]). * dropout: dropout level (default: 0.0). * learning_rate: learning rate (default: [0.005]). :param save_path: path to save the best model (default: 'best_model'). :param config: dictionary containing the description of the model. :param verbose: whether training details should be printed. \"\"\" # Save arguments self . save_path = save_path self . best_config = config self . batch_size = config [ 'batch_size' ] # Create the model self . model = self . _create_model ( self . best_config ) if verbose : self . model . summary () # Train history = self . model . fit ( self . X , self . target , validation_split = 0.1 , epochs = self . best_config [ 'max_epochs' ], batch_size = self . best_config [ 'batch_size' ], verbose = 1 if verbose else 0 ) # Check performance val_mse = history . history [ 'val_loss' ][ - 1 ] # Save the best network self . best_mse = val_mse self . model . save ( self . save_path ) self . best_history = history print ( \"Validation mse:\" , self . best_mse )","title":"custom_model()"},{"location":"CutPredictor/#cut_predictor.Regressor.CutPredictor.data_summary","text":"Displays a summary of the loaded data. Source code in cut_predictor/Regressor.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def data_summary ( self ): \"\"\" Displays a summary of the loaded data. \"\"\" print ( \"Data summary \\n \" + \"-\" * 60 + \" \\n \" ) print ( \"Process parameters:\" ) for param in self . process_parameters : if param in self . categorical_attributes : print ( \" \\t -\" , param , \": categorical \" + str ( self . categorical_values [ param ]) ) else : print ( \" \\t -\" , param , \": numerical [\" , self . min_values [ param ], \" ... \" , self . max_values [ param ], \"]\" ) if self . angle_input : print ( \"Angle variable:\" ) else : print ( \"Position variable:\" ) print ( \" \\t -\" , self . position_attribute , \": numerical,\" , \"[\" , self . min_values [ self . position_attribute ], \"/\" , self . max_values [ self . position_attribute ], \"]\" ) print ( \"Output variable:\" ) print ( \" \\t -\" , self . output_attribute , \": numerical,\" , \"[\" , self . min_values [ self . output_attribute ], \"/\" , self . max_values [ self . output_attribute ], \"]\" ) print ( \" \\n Inputs \\n \" + \"-\" * 60 + \" \\n \" ) print ( self . X . shape ) print ( \" \\n Outputs \\n \" + \"-\" * 60 + \" \\n \" ) print ( self . target . shape )","title":"data_summary()"},{"location":"CutPredictor/#cut_predictor.Regressor.CutPredictor.interactive","text":"Method to interactively vary the process parameters and predict the corresponding cut. Only work in a Jupyter notebook. % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive () Source code in cut_predictor/Regressor.py 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 def interactive ( self ): \"\"\" Method to interactively vary the process parameters and predict the corresponding cut. Only work in a Jupyter notebook. ```python %matplotlib inline plt.rcParams['figure.dpi'] = 150 reg.interactive() ``` \"\"\" values = {} for attr in self . features : if attr == self . position_attribute : continue elif attr in self . categorical_attributes : values [ attr ] = widgets . Dropdown ( options = self . categorical_values [ attr ], value = self . categorical_values [ attr ][ 0 ], ) else : values [ attr ] = widgets . FloatSlider ( value = self . mean_values [ attr ], min = self . min_values [ attr ], max = self . max_values [ attr ], step = ( self . max_values [ attr ] - self . min_values [ attr ]) / 100. , ) display ( widgets . interactive ( self . _visualize , ** values ) )","title":"interactive()"},{"location":"CutPredictor/#cut_predictor.Regressor.CutPredictor.load","text":"Load a pretrained network from a saved folder. The only parameter not saved by default is the batch size. Parameters: Name Type Description Default load_path path to the directory where the best network was saved (default: 'best_model') 'best_model' batch_size batch size to be used (default: 4096). 4096 Source code in cut_predictor/Regressor.py 377 378 379 380 381 382 383 384 385 386 387 388 def load ( self , load_path = 'best_model' , batch_size = 4096 ): \"\"\" Load a pretrained network from a saved folder. The only parameter not saved by default is the batch size. :param load_path: path to the directory where the best network was saved (default: 'best_model') :param batch_size: batch size to be used (default: 4096). \"\"\" self . batch_size = batch_size self . save_path = load_path self . model = tf . keras . models . load_model ( self . save_path )","title":"load()"},{"location":"CutPredictor/#cut_predictor.Regressor.CutPredictor.predict","text":"Predicts the output variable for a given number of input positions (uniformly distributed between the min/max values used for training). Parameters: Name Type Description Default process_parameters dictionary containing the value of all process parameters. required nb_points number of input positions to be used for the prediction. required Source code in cut_predictor/Regressor.py 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 def predict ( self , process_parameters , nb_points ): \"\"\" Predicts the output variable for a given number of input positions (uniformly distributed between the min/max values used for training). :param process_parameters: dictionary containing the value of all process parameters. :param nb_points: number of input positions to be used for the prediction. \"\"\" if self . model is None : print ( \"Error: no model has been trained yet.\" ) return position = np . linspace ( self . min_values [ self . position_attribute ], self . max_values [ self . position_attribute ], nb_points ) X = np . empty (( nb_points , 0 )) for idx , attr in enumerate ( self . features ): if attr == self . position_attribute : if not self . angle_input : values = ( position . reshape (( nb_points , 1 )) - self . mean_values [ attr ] ) / self . std_values [ attr ] X = np . concatenate (( X , values ), axis = 1 ) else : X = np . concatenate ( ( X , np . cos ( position ) . reshape (( nb_points , 1 )) ), axis = 1 ) X = np . concatenate ( ( X , np . sin ( position ) . reshape (( nb_points , 1 )) ), axis = 1 ) elif attr in self . categorical_attributes : code = one_hot ([ process_parameters [ attr ]], self . categorical_values [ attr ]) code = np . repeat ( code , nb_points , axis = 0 ) X = np . concatenate (( X , code ), axis = 1 ) else : val = (( process_parameters [ attr ] - self . mean_values [ attr ] ) / self . std_values [ attr ]) * np . ones (( nb_points , 1 )) X = np . concatenate (( X , val ), axis = 1 ) y = self . model . predict ( X , batch_size = self . batch_size ) y = self . _rescale_output ( y ) return position , y","title":"predict()"},{"location":"CutPredictor/#cut_predictor.Regressor.CutPredictor.training_summary","text":"Creates various plots related to the best network. Can only be called after autotune() or custom_model . You need to finally call plt.show() if you are in a script. Source code in cut_predictor/Regressor.py 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 def training_summary ( self ): \"\"\" Creates various plots related to the best network. Can only be called after ``autotune()`` or ``custom_model``. You need to finally call `plt.show()` if you are in a script. \"\"\" # Training performance plt . figure () plt . plot ( self . best_history . history [ 'loss' ][:], label = \"training\" ) plt . plot ( self . best_history . history [ 'val_loss' ][:], label = \"validation\" ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( \"mse\" ) plt . title ( \"Training performance\" ) plt . legend () plt . savefig ( self . save_path + \"/training.png\" ) y = self . model . predict ( self . X , batch_size = self . batch_size ) plt . figure () plt . scatter ( self . _rescale_output ( self . target ), self . _rescale_output ( y ), s = 1 ) plt . xlabel ( \"Ground truth\" ) plt . ylabel ( \"Prediction\" ) plt . title ( \"Ground truth vs. prediction\" ) plt . savefig ( self . save_path + \"/prediction.png\" ) plt . figure () plt . subplot ( 121 ) plt . hist ( self . _rescale_output ( self . target )) plt . xlabel ( \"Ground truth\" ) plt . subplot ( 122 ) plt . hist ( self . _rescale_output ( y )) plt . xlabel ( \"Prediction\" ) plt . title ( \"Statistics\" ) plt . savefig ( self . save_path + \"/distribution.png\" )","title":"training_summary()"},{"location":"Cut_flange/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Flange cut # import numpy as np import pandas as pd import matplotlib.pyplot as plt plt . rcParams [ 'figure.dpi' ] = 150 # Load the data using pandas data = pd . read_csv ( '../data/cut_flange.csv' ) data = data . head ( - 100 ) # remove last experiment data . head ( 10 ) from cut_predictor import CutPredictor reg = CutPredictor ( data = data , process_parameters = [ 'Material_ID' , 'Niederhalterkraft' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Material_ID' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'c_phi' , output = 'c_z' , angle = True , ) reg . data_summary () Data summary ------------------------------------------------------------ Process parameters: - Material_ID : categorical [1, 2, 3, 4, 5, 6] - Niederhalterkraft : numerical [ 10.0 ... 500.0 ] - Stempel_ID : categorical [2, 3] - Einlegeposition : categorical [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5] - Ziehtiefe : categorical [30, 50, 70] Angle variable: - c_phi : numerical, [ 1.2217304763960306 / 1.5707963267948966 ] Output variable: - c_z : numerical, [ 0.0401206149999993 / 3.6027990824451805 ] Inputs ------------------------------------------------------------ (88000, 25) Outputs ------------------------------------------------------------ (88000,) best_config = reg . autotune ( save_path = 'best_flange_model' , trials = 100 , max_epochs = 100 , layers = [ 3 , 5 ], neurons = [ 64 , 256 , 64 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-5 , 1e-3 ] ) print ( best_config ) config = { 'batch_size' : 4096 , 'max_epochs' : 100 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.001 } # or best_config from autotune if you already did it once reg . custom_model ( save_path = 'best_flange_model' , config = config , verbose = True ) reg . training_summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 128) 3328 dense_1 (Dense) (None, 128) 16512 dense_2 (Dense) (None, 128) 16512 dense_3 (Dense) (None, 128) 16512 dense_4 (Dense) (None, 128) 16512 dense_5 (Dense) (None, 1) 129 ================================================================= Total params: 69,505 Trainable params: 69,505 Non-trainable params: 0 _________________________________________________________________ Epoch 1/100 20/20 [==============================] - 0s 12ms/step - loss: 0.0305 - val_loss: 0.0117 Epoch 2/100 20/20 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0049 Epoch 3/100 20/20 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.0041 Epoch 4/100 20/20 [==============================] - 0s 7ms/step - loss: 0.0024 - val_loss: 0.0037 Epoch 5/100 20/20 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0034 Epoch 6/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0031 Epoch 7/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0027 Epoch 8/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0025 Epoch 9/100 20/20 [==============================] - 0s 8ms/step - loss: 8.4992e-04 - val_loss: 0.0023 Epoch 10/100 20/20 [==============================] - 0s 8ms/step - loss: 6.8574e-04 - val_loss: 0.0021 Epoch 11/100 20/20 [==============================] - 0s 7ms/step - loss: 5.6904e-04 - val_loss: 0.0020 Epoch 12/100 20/20 [==============================] - 0s 7ms/step - loss: 4.8692e-04 - val_loss: 0.0020 Epoch 13/100 20/20 [==============================] - 0s 7ms/step - loss: 4.1945e-04 - val_loss: 0.0019 Epoch 14/100 20/20 [==============================] - 0s 7ms/step - loss: 3.7149e-04 - val_loss: 0.0019 Epoch 15/100 20/20 [==============================] - 0s 7ms/step - loss: 3.3986e-04 - val_loss: 0.0019 Epoch 16/100 20/20 [==============================] - 0s 7ms/step - loss: 3.0665e-04 - val_loss: 0.0019 Epoch 17/100 20/20 [==============================] - 0s 7ms/step - loss: 2.9055e-04 - val_loss: 0.0018 Epoch 18/100 20/20 [==============================] - 0s 7ms/step - loss: 2.6509e-04 - val_loss: 0.0020 Epoch 19/100 20/20 [==============================] - 0s 7ms/step - loss: 2.5699e-04 - val_loss: 0.0019 Epoch 20/100 20/20 [==============================] - 0s 7ms/step - loss: 2.4615e-04 - val_loss: 0.0021 Epoch 21/100 20/20 [==============================] - 0s 7ms/step - loss: 2.2936e-04 - val_loss: 0.0019 Epoch 22/100 20/20 [==============================] - 0s 7ms/step - loss: 2.1117e-04 - val_loss: 0.0019 Epoch 23/100 20/20 [==============================] - 0s 7ms/step - loss: 1.8932e-04 - val_loss: 0.0020 Epoch 24/100 20/20 [==============================] - 0s 7ms/step - loss: 2.0698e-04 - val_loss: 0.0019 Epoch 25/100 20/20 [==============================] - 0s 7ms/step - loss: 2.4872e-04 - val_loss: 0.0020 Epoch 26/100 20/20 [==============================] - 0s 7ms/step - loss: 1.6818e-04 - val_loss: 0.0020 Epoch 27/100 20/20 [==============================] - 0s 7ms/step - loss: 1.4300e-04 - val_loss: 0.0021 Epoch 28/100 20/20 [==============================] - 0s 7ms/step - loss: 1.4494e-04 - val_loss: 0.0020 Epoch 29/100 20/20 [==============================] - 0s 7ms/step - loss: 1.3807e-04 - val_loss: 0.0020 Epoch 30/100 20/20 [==============================] - 0s 7ms/step - loss: 1.3442e-04 - val_loss: 0.0021 Epoch 31/100 20/20 [==============================] - 0s 7ms/step - loss: 1.3699e-04 - val_loss: 0.0021 Epoch 32/100 20/20 [==============================] - 0s 7ms/step - loss: 1.3541e-04 - val_loss: 0.0021 Epoch 33/100 20/20 [==============================] - 0s 7ms/step - loss: 1.1948e-04 - val_loss: 0.0020 Epoch 34/100 20/20 [==============================] - 0s 7ms/step - loss: 9.6147e-05 - val_loss: 0.0020 Epoch 35/100 20/20 [==============================] - 0s 7ms/step - loss: 1.0727e-04 - val_loss: 0.0021 Epoch 36/100 20/20 [==============================] - 0s 7ms/step - loss: 1.8325e-04 - val_loss: 0.0021 Epoch 37/100 20/20 [==============================] - 0s 7ms/step - loss: 9.7300e-05 - val_loss: 0.0021 Epoch 38/100 20/20 [==============================] - 0s 7ms/step - loss: 8.2976e-05 - val_loss: 0.0020 Epoch 39/100 20/20 [==============================] - 0s 7ms/step - loss: 9.0753e-05 - val_loss: 0.0021 Epoch 40/100 20/20 [==============================] - 0s 7ms/step - loss: 9.4111e-05 - val_loss: 0.0021 Epoch 41/100 20/20 [==============================] - 0s 7ms/step - loss: 1.0647e-04 - val_loss: 0.0020 Epoch 42/100 20/20 [==============================] - 0s 7ms/step - loss: 8.4532e-05 - val_loss: 0.0021 Epoch 43/100 20/20 [==============================] - 0s 7ms/step - loss: 7.8181e-05 - val_loss: 0.0021 Epoch 44/100 20/20 [==============================] - 0s 7ms/step - loss: 1.8333e-04 - val_loss: 0.0021 Epoch 45/100 20/20 [==============================] - 0s 7ms/step - loss: 9.4203e-05 - val_loss: 0.0021 Epoch 46/100 20/20 [==============================] - 0s 7ms/step - loss: 6.6704e-05 - val_loss: 0.0021 Epoch 47/100 20/20 [==============================] - 0s 7ms/step - loss: 7.9727e-05 - val_loss: 0.0021 Epoch 48/100 20/20 [==============================] - 0s 7ms/step - loss: 7.0279e-05 - val_loss: 0.0021 Epoch 49/100 20/20 [==============================] - 0s 7ms/step - loss: 6.4674e-05 - val_loss: 0.0021 Epoch 50/100 20/20 [==============================] - 0s 7ms/step - loss: 1.1795e-04 - val_loss: 0.0020 Epoch 51/100 20/20 [==============================] - 0s 7ms/step - loss: 7.0446e-05 - val_loss: 0.0020 Epoch 52/100 20/20 [==============================] - 0s 7ms/step - loss: 7.8976e-05 - val_loss: 0.0021 Epoch 53/100 20/20 [==============================] - 0s 7ms/step - loss: 1.0476e-04 - val_loss: 0.0021 Epoch 54/100 20/20 [==============================] - 0s 7ms/step - loss: 7.8930e-05 - val_loss: 0.0021 Epoch 55/100 20/20 [==============================] - 0s 7ms/step - loss: 5.4941e-05 - val_loss: 0.0021 Epoch 56/100 20/20 [==============================] - 0s 7ms/step - loss: 6.6691e-05 - val_loss: 0.0021 Epoch 57/100 20/20 [==============================] - 0s 7ms/step - loss: 7.9350e-05 - val_loss: 0.0020 Epoch 58/100 20/20 [==============================] - 0s 7ms/step - loss: 5.3135e-05 - val_loss: 0.0020 Epoch 59/100 20/20 [==============================] - 0s 7ms/step - loss: 4.9582e-05 - val_loss: 0.0022 Epoch 60/100 20/20 [==============================] - 0s 7ms/step - loss: 2.9011e-04 - val_loss: 0.0020 Epoch 61/100 20/20 [==============================] - 0s 7ms/step - loss: 7.0972e-05 - val_loss: 0.0020 Epoch 62/100 20/20 [==============================] - 0s 7ms/step - loss: 4.1600e-05 - val_loss: 0.0020 Epoch 63/100 20/20 [==============================] - 0s 7ms/step - loss: 3.8548e-05 - val_loss: 0.0020 Epoch 64/100 20/20 [==============================] - 0s 7ms/step - loss: 3.8583e-05 - val_loss: 0.0020 Epoch 65/100 20/20 [==============================] - 0s 7ms/step - loss: 4.4352e-05 - val_loss: 0.0021 Epoch 66/100 20/20 [==============================] - 0s 7ms/step - loss: 5.0446e-05 - val_loss: 0.0021 Epoch 67/100 20/20 [==============================] - 0s 7ms/step - loss: 3.4677e-05 - val_loss: 0.0021 Epoch 68/100 20/20 [==============================] - 0s 7ms/step - loss: 1.4266e-04 - val_loss: 0.0022 Epoch 69/100 20/20 [==============================] - 0s 7ms/step - loss: 8.9344e-05 - val_loss: 0.0020 Epoch 70/100 20/20 [==============================] - 0s 7ms/step - loss: 3.8991e-05 - val_loss: 0.0020 Epoch 71/100 20/20 [==============================] - 0s 7ms/step - loss: 3.3649e-05 - val_loss: 0.0021 Epoch 72/100 20/20 [==============================] - 0s 7ms/step - loss: 2.8448e-05 - val_loss: 0.0021 Epoch 73/100 20/20 [==============================] - 0s 7ms/step - loss: 2.7862e-05 - val_loss: 0.0021 Epoch 74/100 20/20 [==============================] - 0s 7ms/step - loss: 9.9781e-05 - val_loss: 0.0021 Epoch 75/100 20/20 [==============================] - 0s 7ms/step - loss: 2.9310e-05 - val_loss: 0.0021 Epoch 76/100 20/20 [==============================] - 0s 7ms/step - loss: 4.4288e-05 - val_loss: 0.0021 Epoch 77/100 20/20 [==============================] - 0s 7ms/step - loss: 7.2062e-05 - val_loss: 0.0021 Epoch 78/100 20/20 [==============================] - 0s 7ms/step - loss: 3.4009e-05 - val_loss: 0.0021 Epoch 79/100 20/20 [==============================] - 0s 7ms/step - loss: 4.8673e-05 - val_loss: 0.0020 Epoch 80/100 20/20 [==============================] - 0s 7ms/step - loss: 2.7370e-05 - val_loss: 0.0021 Epoch 81/100 20/20 [==============================] - 0s 7ms/step - loss: 3.9725e-05 - val_loss: 0.0022 Epoch 82/100 20/20 [==============================] - 0s 7ms/step - loss: 4.7084e-05 - val_loss: 0.0020 Epoch 83/100 20/20 [==============================] - 0s 7ms/step - loss: 5.7013e-05 - val_loss: 0.0021 Epoch 84/100 20/20 [==============================] - 0s 7ms/step - loss: 3.3335e-05 - val_loss: 0.0021 Epoch 85/100 20/20 [==============================] - 0s 7ms/step - loss: 6.3882e-05 - val_loss: 0.0022 Epoch 86/100 20/20 [==============================] - 0s 7ms/step - loss: 5.8879e-05 - val_loss: 0.0020 Epoch 87/100 20/20 [==============================] - 0s 7ms/step - loss: 2.3028e-05 - val_loss: 0.0020 Epoch 88/100 20/20 [==============================] - 0s 7ms/step - loss: 1.9815e-05 - val_loss: 0.0020 Epoch 89/100 20/20 [==============================] - 0s 7ms/step - loss: 1.1894e-04 - val_loss: 0.0021 Epoch 90/100 20/20 [==============================] - 0s 7ms/step - loss: 6.7876e-05 - val_loss: 0.0020 Epoch 91/100 20/20 [==============================] - 0s 7ms/step - loss: 2.5176e-05 - val_loss: 0.0020 Epoch 92/100 20/20 [==============================] - 0s 7ms/step - loss: 2.6164e-05 - val_loss: 0.0021 Epoch 93/100 20/20 [==============================] - 0s 7ms/step - loss: 2.5094e-05 - val_loss: 0.0020 Epoch 94/100 20/20 [==============================] - 0s 7ms/step - loss: 3.0745e-05 - val_loss: 0.0021 Epoch 95/100 20/20 [==============================] - 0s 7ms/step - loss: 1.8671e-05 - val_loss: 0.0020 Epoch 96/100 20/20 [==============================] - 0s 7ms/step - loss: 8.7602e-05 - val_loss: 0.0029 Epoch 97/100 20/20 [==============================] - 0s 7ms/step - loss: 2.0655e-04 - val_loss: 0.0020 Epoch 98/100 20/20 [==============================] - 0s 7ms/step - loss: 4.6748e-05 - val_loss: 0.0019 Epoch 99/100 20/20 [==============================] - 0s 7ms/step - loss: 1.9278e-05 - val_loss: 0.0020 Epoch 100/100 20/20 [==============================] - 0s 7ms/step - loss: 1.4813e-05 - val_loss: 0.0020 INFO:tensorflow:Assets written to: best_flange_model/assets Validation mse: 0.001998518593609333 reg . load ( load_path = 'best_flange_model' ) idx = np . random . choice ( 878 ) print ( \"Doe_ID\" , idx + 1 ) reg . compare ( idx * 100 , ( idx + 1 ) * 100 ) Doe_ID 544 % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive ()","title":"Cut flange"},{"location":"Cut_flange/#flange-cut","text":"import numpy as np import pandas as pd import matplotlib.pyplot as plt plt . rcParams [ 'figure.dpi' ] = 150 # Load the data using pandas data = pd . read_csv ( '../data/cut_flange.csv' ) data = data . head ( - 100 ) # remove last experiment data . head ( 10 ) from cut_predictor import CutPredictor reg = CutPredictor ( data = data , process_parameters = [ 'Material_ID' , 'Niederhalterkraft' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Material_ID' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'c_phi' , output = 'c_z' , angle = True , ) reg . data_summary () Data summary ------------------------------------------------------------ Process parameters: - Material_ID : categorical [1, 2, 3, 4, 5, 6] - Niederhalterkraft : numerical [ 10.0 ... 500.0 ] - Stempel_ID : categorical [2, 3] - Einlegeposition : categorical [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5] - Ziehtiefe : categorical [30, 50, 70] Angle variable: - c_phi : numerical, [ 1.2217304763960306 / 1.5707963267948966 ] Output variable: - c_z : numerical, [ 0.0401206149999993 / 3.6027990824451805 ] Inputs ------------------------------------------------------------ (88000, 25) Outputs ------------------------------------------------------------ (88000,) best_config = reg . autotune ( save_path = 'best_flange_model' , trials = 100 , max_epochs = 100 , layers = [ 3 , 5 ], neurons = [ 64 , 256 , 64 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-5 , 1e-3 ] ) print ( best_config ) config = { 'batch_size' : 4096 , 'max_epochs' : 100 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.001 } # or best_config from autotune if you already did it once reg . custom_model ( save_path = 'best_flange_model' , config = config , verbose = True ) reg . training_summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 128) 3328 dense_1 (Dense) (None, 128) 16512 dense_2 (Dense) (None, 128) 16512 dense_3 (Dense) (None, 128) 16512 dense_4 (Dense) (None, 128) 16512 dense_5 (Dense) (None, 1) 129 ================================================================= Total params: 69,505 Trainable params: 69,505 Non-trainable params: 0 _________________________________________________________________ Epoch 1/100 20/20 [==============================] - 0s 12ms/step - loss: 0.0305 - val_loss: 0.0117 Epoch 2/100 20/20 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0049 Epoch 3/100 20/20 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.0041 Epoch 4/100 20/20 [==============================] - 0s 7ms/step - loss: 0.0024 - val_loss: 0.0037 Epoch 5/100 20/20 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0034 Epoch 6/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0031 Epoch 7/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0027 Epoch 8/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0025 Epoch 9/100 20/20 [==============================] - 0s 8ms/step - loss: 8.4992e-04 - val_loss: 0.0023 Epoch 10/100 20/20 [==============================] - 0s 8ms/step - loss: 6.8574e-04 - val_loss: 0.0021 Epoch 11/100 20/20 [==============================] - 0s 7ms/step - loss: 5.6904e-04 - val_loss: 0.0020 Epoch 12/100 20/20 [==============================] - 0s 7ms/step - loss: 4.8692e-04 - val_loss: 0.0020 Epoch 13/100 20/20 [==============================] - 0s 7ms/step - loss: 4.1945e-04 - val_loss: 0.0019 Epoch 14/100 20/20 [==============================] - 0s 7ms/step - loss: 3.7149e-04 - val_loss: 0.0019 Epoch 15/100 20/20 [==============================] - 0s 7ms/step - loss: 3.3986e-04 - val_loss: 0.0019 Epoch 16/100 20/20 [==============================] - 0s 7ms/step - loss: 3.0665e-04 - val_loss: 0.0019 Epoch 17/100 20/20 [==============================] - 0s 7ms/step - loss: 2.9055e-04 - val_loss: 0.0018 Epoch 18/100 20/20 [==============================] - 0s 7ms/step - loss: 2.6509e-04 - val_loss: 0.0020 Epoch 19/100 20/20 [==============================] - 0s 7ms/step - loss: 2.5699e-04 - val_loss: 0.0019 Epoch 20/100 20/20 [==============================] - 0s 7ms/step - loss: 2.4615e-04 - val_loss: 0.0021 Epoch 21/100 20/20 [==============================] - 0s 7ms/step - loss: 2.2936e-04 - val_loss: 0.0019 Epoch 22/100 20/20 [==============================] - 0s 7ms/step - loss: 2.1117e-04 - val_loss: 0.0019 Epoch 23/100 20/20 [==============================] - 0s 7ms/step - loss: 1.8932e-04 - val_loss: 0.0020 Epoch 24/100 20/20 [==============================] - 0s 7ms/step - loss: 2.0698e-04 - val_loss: 0.0019 Epoch 25/100 20/20 [==============================] - 0s 7ms/step - loss: 2.4872e-04 - val_loss: 0.0020 Epoch 26/100 20/20 [==============================] - 0s 7ms/step - loss: 1.6818e-04 - val_loss: 0.0020 Epoch 27/100 20/20 [==============================] - 0s 7ms/step - loss: 1.4300e-04 - val_loss: 0.0021 Epoch 28/100 20/20 [==============================] - 0s 7ms/step - loss: 1.4494e-04 - val_loss: 0.0020 Epoch 29/100 20/20 [==============================] - 0s 7ms/step - loss: 1.3807e-04 - val_loss: 0.0020 Epoch 30/100 20/20 [==============================] - 0s 7ms/step - loss: 1.3442e-04 - val_loss: 0.0021 Epoch 31/100 20/20 [==============================] - 0s 7ms/step - loss: 1.3699e-04 - val_loss: 0.0021 Epoch 32/100 20/20 [==============================] - 0s 7ms/step - loss: 1.3541e-04 - val_loss: 0.0021 Epoch 33/100 20/20 [==============================] - 0s 7ms/step - loss: 1.1948e-04 - val_loss: 0.0020 Epoch 34/100 20/20 [==============================] - 0s 7ms/step - loss: 9.6147e-05 - val_loss: 0.0020 Epoch 35/100 20/20 [==============================] - 0s 7ms/step - loss: 1.0727e-04 - val_loss: 0.0021 Epoch 36/100 20/20 [==============================] - 0s 7ms/step - loss: 1.8325e-04 - val_loss: 0.0021 Epoch 37/100 20/20 [==============================] - 0s 7ms/step - loss: 9.7300e-05 - val_loss: 0.0021 Epoch 38/100 20/20 [==============================] - 0s 7ms/step - loss: 8.2976e-05 - val_loss: 0.0020 Epoch 39/100 20/20 [==============================] - 0s 7ms/step - loss: 9.0753e-05 - val_loss: 0.0021 Epoch 40/100 20/20 [==============================] - 0s 7ms/step - loss: 9.4111e-05 - val_loss: 0.0021 Epoch 41/100 20/20 [==============================] - 0s 7ms/step - loss: 1.0647e-04 - val_loss: 0.0020 Epoch 42/100 20/20 [==============================] - 0s 7ms/step - loss: 8.4532e-05 - val_loss: 0.0021 Epoch 43/100 20/20 [==============================] - 0s 7ms/step - loss: 7.8181e-05 - val_loss: 0.0021 Epoch 44/100 20/20 [==============================] - 0s 7ms/step - loss: 1.8333e-04 - val_loss: 0.0021 Epoch 45/100 20/20 [==============================] - 0s 7ms/step - loss: 9.4203e-05 - val_loss: 0.0021 Epoch 46/100 20/20 [==============================] - 0s 7ms/step - loss: 6.6704e-05 - val_loss: 0.0021 Epoch 47/100 20/20 [==============================] - 0s 7ms/step - loss: 7.9727e-05 - val_loss: 0.0021 Epoch 48/100 20/20 [==============================] - 0s 7ms/step - loss: 7.0279e-05 - val_loss: 0.0021 Epoch 49/100 20/20 [==============================] - 0s 7ms/step - loss: 6.4674e-05 - val_loss: 0.0021 Epoch 50/100 20/20 [==============================] - 0s 7ms/step - loss: 1.1795e-04 - val_loss: 0.0020 Epoch 51/100 20/20 [==============================] - 0s 7ms/step - loss: 7.0446e-05 - val_loss: 0.0020 Epoch 52/100 20/20 [==============================] - 0s 7ms/step - loss: 7.8976e-05 - val_loss: 0.0021 Epoch 53/100 20/20 [==============================] - 0s 7ms/step - loss: 1.0476e-04 - val_loss: 0.0021 Epoch 54/100 20/20 [==============================] - 0s 7ms/step - loss: 7.8930e-05 - val_loss: 0.0021 Epoch 55/100 20/20 [==============================] - 0s 7ms/step - loss: 5.4941e-05 - val_loss: 0.0021 Epoch 56/100 20/20 [==============================] - 0s 7ms/step - loss: 6.6691e-05 - val_loss: 0.0021 Epoch 57/100 20/20 [==============================] - 0s 7ms/step - loss: 7.9350e-05 - val_loss: 0.0020 Epoch 58/100 20/20 [==============================] - 0s 7ms/step - loss: 5.3135e-05 - val_loss: 0.0020 Epoch 59/100 20/20 [==============================] - 0s 7ms/step - loss: 4.9582e-05 - val_loss: 0.0022 Epoch 60/100 20/20 [==============================] - 0s 7ms/step - loss: 2.9011e-04 - val_loss: 0.0020 Epoch 61/100 20/20 [==============================] - 0s 7ms/step - loss: 7.0972e-05 - val_loss: 0.0020 Epoch 62/100 20/20 [==============================] - 0s 7ms/step - loss: 4.1600e-05 - val_loss: 0.0020 Epoch 63/100 20/20 [==============================] - 0s 7ms/step - loss: 3.8548e-05 - val_loss: 0.0020 Epoch 64/100 20/20 [==============================] - 0s 7ms/step - loss: 3.8583e-05 - val_loss: 0.0020 Epoch 65/100 20/20 [==============================] - 0s 7ms/step - loss: 4.4352e-05 - val_loss: 0.0021 Epoch 66/100 20/20 [==============================] - 0s 7ms/step - loss: 5.0446e-05 - val_loss: 0.0021 Epoch 67/100 20/20 [==============================] - 0s 7ms/step - loss: 3.4677e-05 - val_loss: 0.0021 Epoch 68/100 20/20 [==============================] - 0s 7ms/step - loss: 1.4266e-04 - val_loss: 0.0022 Epoch 69/100 20/20 [==============================] - 0s 7ms/step - loss: 8.9344e-05 - val_loss: 0.0020 Epoch 70/100 20/20 [==============================] - 0s 7ms/step - loss: 3.8991e-05 - val_loss: 0.0020 Epoch 71/100 20/20 [==============================] - 0s 7ms/step - loss: 3.3649e-05 - val_loss: 0.0021 Epoch 72/100 20/20 [==============================] - 0s 7ms/step - loss: 2.8448e-05 - val_loss: 0.0021 Epoch 73/100 20/20 [==============================] - 0s 7ms/step - loss: 2.7862e-05 - val_loss: 0.0021 Epoch 74/100 20/20 [==============================] - 0s 7ms/step - loss: 9.9781e-05 - val_loss: 0.0021 Epoch 75/100 20/20 [==============================] - 0s 7ms/step - loss: 2.9310e-05 - val_loss: 0.0021 Epoch 76/100 20/20 [==============================] - 0s 7ms/step - loss: 4.4288e-05 - val_loss: 0.0021 Epoch 77/100 20/20 [==============================] - 0s 7ms/step - loss: 7.2062e-05 - val_loss: 0.0021 Epoch 78/100 20/20 [==============================] - 0s 7ms/step - loss: 3.4009e-05 - val_loss: 0.0021 Epoch 79/100 20/20 [==============================] - 0s 7ms/step - loss: 4.8673e-05 - val_loss: 0.0020 Epoch 80/100 20/20 [==============================] - 0s 7ms/step - loss: 2.7370e-05 - val_loss: 0.0021 Epoch 81/100 20/20 [==============================] - 0s 7ms/step - loss: 3.9725e-05 - val_loss: 0.0022 Epoch 82/100 20/20 [==============================] - 0s 7ms/step - loss: 4.7084e-05 - val_loss: 0.0020 Epoch 83/100 20/20 [==============================] - 0s 7ms/step - loss: 5.7013e-05 - val_loss: 0.0021 Epoch 84/100 20/20 [==============================] - 0s 7ms/step - loss: 3.3335e-05 - val_loss: 0.0021 Epoch 85/100 20/20 [==============================] - 0s 7ms/step - loss: 6.3882e-05 - val_loss: 0.0022 Epoch 86/100 20/20 [==============================] - 0s 7ms/step - loss: 5.8879e-05 - val_loss: 0.0020 Epoch 87/100 20/20 [==============================] - 0s 7ms/step - loss: 2.3028e-05 - val_loss: 0.0020 Epoch 88/100 20/20 [==============================] - 0s 7ms/step - loss: 1.9815e-05 - val_loss: 0.0020 Epoch 89/100 20/20 [==============================] - 0s 7ms/step - loss: 1.1894e-04 - val_loss: 0.0021 Epoch 90/100 20/20 [==============================] - 0s 7ms/step - loss: 6.7876e-05 - val_loss: 0.0020 Epoch 91/100 20/20 [==============================] - 0s 7ms/step - loss: 2.5176e-05 - val_loss: 0.0020 Epoch 92/100 20/20 [==============================] - 0s 7ms/step - loss: 2.6164e-05 - val_loss: 0.0021 Epoch 93/100 20/20 [==============================] - 0s 7ms/step - loss: 2.5094e-05 - val_loss: 0.0020 Epoch 94/100 20/20 [==============================] - 0s 7ms/step - loss: 3.0745e-05 - val_loss: 0.0021 Epoch 95/100 20/20 [==============================] - 0s 7ms/step - loss: 1.8671e-05 - val_loss: 0.0020 Epoch 96/100 20/20 [==============================] - 0s 7ms/step - loss: 8.7602e-05 - val_loss: 0.0029 Epoch 97/100 20/20 [==============================] - 0s 7ms/step - loss: 2.0655e-04 - val_loss: 0.0020 Epoch 98/100 20/20 [==============================] - 0s 7ms/step - loss: 4.6748e-05 - val_loss: 0.0019 Epoch 99/100 20/20 [==============================] - 0s 7ms/step - loss: 1.9278e-05 - val_loss: 0.0020 Epoch 100/100 20/20 [==============================] - 0s 7ms/step - loss: 1.4813e-05 - val_loss: 0.0020 INFO:tensorflow:Assets written to: best_flange_model/assets Validation mse: 0.001998518593609333 reg . load ( load_path = 'best_flange_model' ) idx = np . random . choice ( 878 ) print ( \"Doe_ID\" , idx + 1 ) reg . compare ( idx * 100 , ( idx + 1 ) * 100 ) Doe_ID 544 % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive ()","title":"Flange cut"},{"location":"Cut_web/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Web cut # import numpy as np import pandas as pd import matplotlib.pyplot as plt plt . rcParams [ 'figure.dpi' ] = 150 # Load the data using pandas data = pd . read_csv ( '../data/cut_web.csv' ) data = data . head ( - 100 ) # remove last experiment data . head ( 10 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } doe_id Material_ID Blechdicke Niederhalterkraft Ziehspalt Stempel_ID Einlegeposition Ziehtiefe Breite UG OG E Material_Name Rp0 Rp0.2 Rp100 Rp25 Rp50 c_phi c_rho 0 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.221730 463.681714 1 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.225256 463.680524 2 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.228782 463.678661 3 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.232308 463.708276 4 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.235834 463.736364 5 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.239360 463.753995 6 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.242886 463.795277 7 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.246412 463.832735 8 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.249938 463.881185 9 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.253464 463.918497 from cut_predictor import CutPredictor reg = CutPredictor ( data = data , process_parameters = [ 'Material_ID' , 'Niederhalterkraft' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Material_ID' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'c_phi' , output = 'c_rho' , angle = True , ) reg . data_summary () Data summary ------------------------------------------------------------ Process parameters: - Material_ID : categorical [1, 2, 3, 4, 5, 6] - Niederhalterkraft : numerical [ 10.0 ... 500.0 ] - Stempel_ID : categorical [2, 3] - Einlegeposition : categorical [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5] - Ziehtiefe : categorical [30, 50, 70] Angle variable: - c_phi : numerical, [ 1.2217304763960306 / 1.5707963267948966 ] Output variable: - c_rho : numerical, [ 462.8938277335998 / 465.1706438896841 ] Inputs ------------------------------------------------------------ (88000, 25) Outputs ------------------------------------------------------------ (88000,) best_config = reg . autotune ( save_path = 'best_web_model' , trials = 100 , max_epochs = 100 , layers = [ 2 , 4 ], neurons = [ 64 , 256 , 64 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-5 , 1e-3 ] ) print ( best_config ) config = { 'batch_size' : 4096 , 'max_epochs' : 100 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.1 , 'learning_rate' : 0.001 } # or best_config from autotune if you already did it once reg . custom_model ( save_path = 'best_web_model' , config = config , verbose = True ) reg . training_summary () Metal device set to: Apple M1 Pro systemMemory: 16.00 GB maxCacheSize: 5.33 GB Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 128) 3328 dropout (Dropout) (None, 128) 0 dense_1 (Dense) (None, 128) 16512 dropout_1 (Dropout) (None, 128) 0 dense_2 (Dense) (None, 128) 16512 dropout_2 (Dropout) (None, 128) 0 dense_3 (Dense) (None, 128) 16512 dropout_3 (Dropout) (None, 128) 0 dense_4 (Dense) (None, 128) 16512 dropout_4 (Dropout) (None, 128) 0 dense_5 (Dense) (None, 1) 129 ================================================================= Total params: 69,505 Trainable params: 69,505 Non-trainable params: 0 _________________________________________________________________ Epoch 1/100 20/20 [==============================] - 1s 15ms/step - loss: 0.0387 - val_loss: 0.0230 Epoch 2/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0176 Epoch 3/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0167 Epoch 4/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0157 Epoch 5/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0164 Epoch 6/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0159 Epoch 7/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0154 Epoch 8/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0144 Epoch 9/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0145 Epoch 10/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0133 Epoch 11/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0126 Epoch 12/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0120 Epoch 13/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0122 Epoch 14/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0124 Epoch 15/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0104 Epoch 16/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0115 Epoch 17/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0106 Epoch 18/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0087 Epoch 19/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0103 Epoch 20/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0079 Epoch 21/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0079 Epoch 22/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0074 Epoch 23/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0069 Epoch 24/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0069 Epoch 25/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0068 Epoch 26/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0058 Epoch 27/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0070 Epoch 28/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0058 Epoch 29/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0066 Epoch 30/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0055 Epoch 31/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0061 Epoch 32/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0055 Epoch 33/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0056 Epoch 34/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0062 Epoch 35/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0054 Epoch 36/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0053 Epoch 37/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0050 Epoch 38/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0052 Epoch 39/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0052 Epoch 40/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0055 Epoch 41/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0050 Epoch 42/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0053 Epoch 43/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0054 Epoch 44/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0048 Epoch 45/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0050 Epoch 46/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0053 Epoch 47/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0049 Epoch 48/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0051 Epoch 49/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0047 Epoch 50/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0046 Epoch 51/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0048 Epoch 52/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0052 Epoch 53/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0048 Epoch 54/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0047 Epoch 55/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0050 Epoch 56/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0047 Epoch 57/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0051 Epoch 58/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0045 Epoch 59/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0049 Epoch 60/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0047 Epoch 61/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0047 Epoch 62/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0046 Epoch 63/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0042 Epoch 64/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0047 Epoch 65/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0041 Epoch 66/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0049 Epoch 67/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0042 Epoch 68/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0044 Epoch 69/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0045 Epoch 70/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0044 Epoch 71/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0044 Epoch 72/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0045 Epoch 73/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0042 Epoch 74/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0046 Epoch 75/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0044 Epoch 76/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0042 Epoch 77/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0044 Epoch 78/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0041 Epoch 79/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0045 Epoch 80/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0043 Epoch 81/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0045 Epoch 82/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0042 Epoch 83/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0043 Epoch 84/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0042 Epoch 85/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0043 Epoch 86/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0042 Epoch 87/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0042 Epoch 88/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0045 Epoch 89/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0042 Epoch 90/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0041 Epoch 91/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0043 Epoch 92/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0042 Epoch 93/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0042 Epoch 94/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0041 Epoch 95/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0043 Epoch 96/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0043 Epoch 97/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0041 Epoch 98/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0040 Epoch 99/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0048 Epoch 100/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0044 INFO:tensorflow:Assets written to: best_web_model/assets Validation mse: 0.004361927043646574 reg . load ( load_path = 'best_web_model' ) idx = np . random . choice ( 878 ) print ( \"Doe_ID\" , idx + 1 ) reg . compare ( idx * 100 , ( idx + 1 ) * 100 ) Doe_ID 641 % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive () interactive(children=(Dropdown(description='Material_ID', options=(1, 2, 3, 4, 5, 6), value=1), FloatSlider(va\u2026","title":"Cut web"},{"location":"Cut_web/#web-cut","text":"import numpy as np import pandas as pd import matplotlib.pyplot as plt plt . rcParams [ 'figure.dpi' ] = 150 # Load the data using pandas data = pd . read_csv ( '../data/cut_web.csv' ) data = data . head ( - 100 ) # remove last experiment data . head ( 10 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } doe_id Material_ID Blechdicke Niederhalterkraft Ziehspalt Stempel_ID Einlegeposition Ziehtiefe Breite UG OG E Material_Name Rp0 Rp0.2 Rp100 Rp25 Rp50 c_phi c_rho 0 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.221730 463.681714 1 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.225256 463.680524 2 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.228782 463.678661 3 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.232308 463.708276 4 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.235834 463.736364 5 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.239360 463.753995 6 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.242886 463.795277 7 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.246412 463.832735 8 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.249938 463.881185 9 1 3 1.01 410 2.4 3 -5 30 70.2 1.71 2.0 191.37245 DC04_1.00mm 138.22696 147.601859 534.002871 377.443009 449.528189 1.253464 463.918497 from cut_predictor import CutPredictor reg = CutPredictor ( data = data , process_parameters = [ 'Material_ID' , 'Niederhalterkraft' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Material_ID' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'c_phi' , output = 'c_rho' , angle = True , ) reg . data_summary () Data summary ------------------------------------------------------------ Process parameters: - Material_ID : categorical [1, 2, 3, 4, 5, 6] - Niederhalterkraft : numerical [ 10.0 ... 500.0 ] - Stempel_ID : categorical [2, 3] - Einlegeposition : categorical [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5] - Ziehtiefe : categorical [30, 50, 70] Angle variable: - c_phi : numerical, [ 1.2217304763960306 / 1.5707963267948966 ] Output variable: - c_rho : numerical, [ 462.8938277335998 / 465.1706438896841 ] Inputs ------------------------------------------------------------ (88000, 25) Outputs ------------------------------------------------------------ (88000,) best_config = reg . autotune ( save_path = 'best_web_model' , trials = 100 , max_epochs = 100 , layers = [ 2 , 4 ], neurons = [ 64 , 256 , 64 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-5 , 1e-3 ] ) print ( best_config ) config = { 'batch_size' : 4096 , 'max_epochs' : 100 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.1 , 'learning_rate' : 0.001 } # or best_config from autotune if you already did it once reg . custom_model ( save_path = 'best_web_model' , config = config , verbose = True ) reg . training_summary () Metal device set to: Apple M1 Pro systemMemory: 16.00 GB maxCacheSize: 5.33 GB Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 128) 3328 dropout (Dropout) (None, 128) 0 dense_1 (Dense) (None, 128) 16512 dropout_1 (Dropout) (None, 128) 0 dense_2 (Dense) (None, 128) 16512 dropout_2 (Dropout) (None, 128) 0 dense_3 (Dense) (None, 128) 16512 dropout_3 (Dropout) (None, 128) 0 dense_4 (Dense) (None, 128) 16512 dropout_4 (Dropout) (None, 128) 0 dense_5 (Dense) (None, 1) 129 ================================================================= Total params: 69,505 Trainable params: 69,505 Non-trainable params: 0 _________________________________________________________________ Epoch 1/100 20/20 [==============================] - 1s 15ms/step - loss: 0.0387 - val_loss: 0.0230 Epoch 2/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0176 Epoch 3/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0167 Epoch 4/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0157 Epoch 5/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0164 Epoch 6/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0159 Epoch 7/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0154 Epoch 8/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0144 Epoch 9/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0145 Epoch 10/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0133 Epoch 11/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0126 Epoch 12/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0120 Epoch 13/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0122 Epoch 14/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0124 Epoch 15/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0104 Epoch 16/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0115 Epoch 17/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0106 Epoch 18/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0087 Epoch 19/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0103 Epoch 20/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0079 Epoch 21/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0079 Epoch 22/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0074 Epoch 23/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0069 Epoch 24/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0069 Epoch 25/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0068 Epoch 26/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0058 Epoch 27/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0070 Epoch 28/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0058 Epoch 29/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0066 Epoch 30/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0055 Epoch 31/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0061 Epoch 32/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0055 Epoch 33/100 20/20 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0056 Epoch 34/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0062 Epoch 35/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0054 Epoch 36/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0053 Epoch 37/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0050 Epoch 38/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0052 Epoch 39/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0052 Epoch 40/100 20/20 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0055 Epoch 41/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0050 Epoch 42/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0053 Epoch 43/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0054 Epoch 44/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0048 Epoch 45/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0050 Epoch 46/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0053 Epoch 47/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0049 Epoch 48/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0051 Epoch 49/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0047 Epoch 50/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0046 Epoch 51/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0048 Epoch 52/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0052 Epoch 53/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0048 Epoch 54/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0047 Epoch 55/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0050 Epoch 56/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0047 Epoch 57/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0051 Epoch 58/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0045 Epoch 59/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0049 Epoch 60/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0047 Epoch 61/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0047 Epoch 62/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0046 Epoch 63/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0042 Epoch 64/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0047 Epoch 65/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0041 Epoch 66/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0049 Epoch 67/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0042 Epoch 68/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0044 Epoch 69/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0045 Epoch 70/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0044 Epoch 71/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0044 Epoch 72/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0045 Epoch 73/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0042 Epoch 74/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0046 Epoch 75/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0044 Epoch 76/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0042 Epoch 77/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0044 Epoch 78/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0041 Epoch 79/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0045 Epoch 80/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0043 Epoch 81/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0045 Epoch 82/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0042 Epoch 83/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0043 Epoch 84/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0042 Epoch 85/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0043 Epoch 86/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0042 Epoch 87/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0042 Epoch 88/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0045 Epoch 89/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0042 Epoch 90/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0041 Epoch 91/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0043 Epoch 92/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0042 Epoch 93/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0042 Epoch 94/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0041 Epoch 95/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0043 Epoch 96/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0043 Epoch 97/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0041 Epoch 98/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0040 Epoch 99/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0048 Epoch 100/100 20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0044 INFO:tensorflow:Assets written to: best_web_model/assets Validation mse: 0.004361927043646574 reg . load ( load_path = 'best_web_model' ) idx = np . random . choice ( 878 ) print ( \"Doe_ID\" , idx + 1 ) reg . compare ( idx * 100 , ( idx + 1 ) * 100 ) Doe_ID 641 % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive () interactive(children=(Dropdown(description='Material_ID', options=(1, 2, 3, 4, 5, 6), value=1), FloatSlider(va\u2026","title":"Web cut"},{"location":"Cut_x0/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); x0 cut prediction # import numpy as np import pandas as pd import matplotlib.pyplot as plt plt . rcParams [ 'figure.dpi' ] = 150 Loading the data # # Load the data using pandas data = pd . read_csv ( '../data/cut_x0.csv' ) data = data . head ( - 1000 ) # remove last experiment data . head ( 10 ) Creating the regressor # from cut_predictor import CutPredictor reg = CutPredictor ( data = data , process_parameters = [ 'Blechdicke' , 'Niederhalterkraft' , 'Ziehspalt' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Ziehspalt' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'tp' , output = 'deviationc' ) # Print a summary of the data reg . data_summary () Data summary ------------------------------------------------------------ Process parameters: - Blechdicke : numerical [ 0.99 ... 1.48 ] - Niederhalterkraft : numerical [ 10.0 ... 500.0 ] - Ziehspalt : categorical [1.6, 2.4] - Einlegeposition : categorical [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5] - Ziehtiefe : categorical [30, 50, 70] Position variable: - tp : numerical, [ 0.0 / 5.0 ] Output variable: - deviationc : numerical, [ -3.16506211149574 / 7.228601057768613 ] Inputs ------------------------------------------------------------ (880000, 19) Outputs ------------------------------------------------------------ (880000,) Training methods # Autotuning # best_config = reg . autotune ( save_path = 'best_x0_model' , trials = 100 , max_epochs = 50 , layers = [ 3 , 5 ], neurons = [ 64 , 256 , 64 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-5 , 1e-3 ] ) reg . training_summary () Alternative: define a custom network and do the optimization yourself # One can also run the autotuning for a limited number of epochs and then fine-tune the best configuration by training it longer. config = { 'batch_size' : 4096 , 'max_epochs' : 50 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 } # or best_config from autotune if you already did it once reg . custom_model ( save_path = 'best_x0_model' , config = config , verbose = True ) reg . training_summary () Metal device set to: Apple M1 Pro systemMemory: 16.00 GB maxCacheSize: 5.33 GB Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 128) 2560 dense_1 (Dense) (None, 128) 16512 dense_2 (Dense) (None, 128) 16512 dense_3 (Dense) (None, 128) 16512 dense_4 (Dense) (None, 128) 16512 dense_5 (Dense) (None, 1) 129 ================================================================= Total params: 68,737 Trainable params: 68,737 Non-trainable params: 0 _________________________________________________________________ Epoch 1/50 194/194 [==============================] - 2s 7ms/step - loss: 0.0192 - val_loss: 0.0018 Epoch 2/50 194/194 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013 Epoch 3/50 194/194 [==============================] - 1s 7ms/step - loss: 9.9587e-04 - val_loss: 0.0011 Epoch 4/50 194/194 [==============================] - 1s 7ms/step - loss: 8.5166e-04 - val_loss: 0.0011 Epoch 5/50 194/194 [==============================] - 1s 6ms/step - loss: 7.6869e-04 - val_loss: 9.9730e-04 Epoch 6/50 194/194 [==============================] - 1s 7ms/step - loss: 6.6825e-04 - val_loss: 8.9133e-04 Epoch 7/50 194/194 [==============================] - 1s 7ms/step - loss: 6.2191e-04 - val_loss: 8.3773e-04 Epoch 8/50 194/194 [==============================] - 1s 7ms/step - loss: 5.9185e-04 - val_loss: 9.7526e-04 Epoch 9/50 194/194 [==============================] - 1s 7ms/step - loss: 5.6919e-04 - val_loss: 8.8830e-04 Epoch 10/50 194/194 [==============================] - 1s 7ms/step - loss: 5.1496e-04 - val_loss: 7.7968e-04 Epoch 11/50 194/194 [==============================] - 1s 7ms/step - loss: 4.8956e-04 - val_loss: 7.8011e-04 Epoch 12/50 194/194 [==============================] - 1s 6ms/step - loss: 4.6958e-04 - val_loss: 7.5043e-04 Epoch 13/50 194/194 [==============================] - 1s 7ms/step - loss: 4.4460e-04 - val_loss: 7.7862e-04 Epoch 14/50 194/194 [==============================] - 1s 6ms/step - loss: 4.2258e-04 - val_loss: 8.3322e-04 Epoch 15/50 194/194 [==============================] - 1s 7ms/step - loss: 4.0747e-04 - val_loss: 7.5810e-04 Epoch 16/50 194/194 [==============================] - 1s 7ms/step - loss: 3.9185e-04 - val_loss: 7.2246e-04 Epoch 17/50 194/194 [==============================] - 1s 6ms/step - loss: 3.6418e-04 - val_loss: 7.2556e-04 Epoch 18/50 194/194 [==============================] - 1s 6ms/step - loss: 3.6550e-04 - val_loss: 7.0186e-04 Epoch 19/50 194/194 [==============================] - 1s 7ms/step - loss: 3.5533e-04 - val_loss: 7.8825e-04 Epoch 20/50 194/194 [==============================] - 1s 6ms/step - loss: 3.2706e-04 - val_loss: 8.1836e-04 Epoch 21/50 194/194 [==============================] - 1s 7ms/step - loss: 3.2028e-04 - val_loss: 7.0829e-04 Epoch 22/50 194/194 [==============================] - 1s 7ms/step - loss: 3.1008e-04 - val_loss: 7.9029e-04 Epoch 23/50 194/194 [==============================] - 1s 7ms/step - loss: 3.0182e-04 - val_loss: 6.6371e-04 Epoch 24/50 194/194 [==============================] - 1s 7ms/step - loss: 2.9043e-04 - val_loss: 8.6761e-04 Epoch 25/50 194/194 [==============================] - 1s 7ms/step - loss: 2.8357e-04 - val_loss: 7.1200e-04 Epoch 26/50 194/194 [==============================] - 1s 7ms/step - loss: 2.7604e-04 - val_loss: 6.7895e-04 Epoch 27/50 194/194 [==============================] - 1s 7ms/step - loss: 2.7605e-04 - val_loss: 6.6027e-04 Epoch 28/50 194/194 [==============================] - 1s 7ms/step - loss: 2.6710e-04 - val_loss: 6.5750e-04 Epoch 29/50 194/194 [==============================] - 1s 6ms/step - loss: 2.4262e-04 - val_loss: 6.8879e-04 Epoch 30/50 194/194 [==============================] - 1s 7ms/step - loss: 2.3386e-04 - val_loss: 7.2790e-04 Epoch 31/50 194/194 [==============================] - 1s 6ms/step - loss: 2.2975e-04 - val_loss: 6.2066e-04 Epoch 32/50 194/194 [==============================] - 1s 7ms/step - loss: 2.1958e-04 - val_loss: 6.4486e-04 Epoch 33/50 194/194 [==============================] - 1s 7ms/step - loss: 2.1594e-04 - val_loss: 6.7419e-04 Epoch 34/50 194/194 [==============================] - 1s 6ms/step - loss: 2.1231e-04 - val_loss: 7.2574e-04 Epoch 35/50 194/194 [==============================] - 1s 6ms/step - loss: 1.9914e-04 - val_loss: 6.5656e-04 Epoch 36/50 194/194 [==============================] - 1s 7ms/step - loss: 1.9153e-04 - val_loss: 7.1846e-04 Epoch 37/50 194/194 [==============================] - 1s 7ms/step - loss: 2.0060e-04 - val_loss: 6.6978e-04 Epoch 38/50 194/194 [==============================] - 1s 6ms/step - loss: 1.7992e-04 - val_loss: 6.6546e-04 Epoch 39/50 194/194 [==============================] - 1s 7ms/step - loss: 1.7609e-04 - val_loss: 7.3219e-04 Epoch 40/50 194/194 [==============================] - 1s 7ms/step - loss: 1.7318e-04 - val_loss: 7.1188e-04 Epoch 41/50 194/194 [==============================] - 1s 7ms/step - loss: 1.5796e-04 - val_loss: 6.9973e-04 Epoch 42/50 194/194 [==============================] - 1s 7ms/step - loss: 1.5774e-04 - val_loss: 6.7213e-04 Epoch 43/50 194/194 [==============================] - 1s 7ms/step - loss: 1.4236e-04 - val_loss: 6.9006e-04 Epoch 44/50 194/194 [==============================] - 1s 7ms/step - loss: 1.5219e-04 - val_loss: 6.8170e-04 Epoch 45/50 194/194 [==============================] - 1s 7ms/step - loss: 1.2968e-04 - val_loss: 6.9588e-04 Epoch 46/50 194/194 [==============================] - 1s 7ms/step - loss: 1.3347e-04 - val_loss: 6.7843e-04 Epoch 47/50 194/194 [==============================] - 1s 7ms/step - loss: 1.1999e-04 - val_loss: 6.1209e-04 Epoch 48/50 194/194 [==============================] - 1s 7ms/step - loss: 1.2297e-04 - val_loss: 6.2921e-04 Epoch 49/50 194/194 [==============================] - 1s 7ms/step - loss: 1.4646e-04 - val_loss: 6.1986e-04 Epoch 50/50 194/194 [==============================] - 1s 6ms/step - loss: 1.0288e-04 - val_loss: 6.1435e-04 INFO:tensorflow:Assets written to: best_x0_model/assets Validation mse: 0.0006143474020063877 Other alternative: the model has already been trained # We just need to reload it to make predictions. reg . load ( load_path = 'best_x0_model' ) Metal device set to: Apple M1 Pro systemMemory: 16.00 GB maxCacheSize: 5.33 GB Visualization # Prediction for single process parameter values # x , y = reg . predict ({ 'Blechdicke' : 1.01 , 'Niederhalterkraft' : 410.0 , 'Ziehspalt' : 2.4 , 'Einlegeposition' : - 5 , 'Ziehtiefe' : 30 }, nb_points = 1000 ) plt . figure () plt . plot ( x , y ) plt . xlabel ( 'tp' ) plt . ylabel ( 'deviationc' ) Text(0, 0.5, 'deviationc') Comparison with the ground truth on the training set # Randomly choose an id between 0 and 877 and compare the prediction to the ground truth. idx = np . random . choice ( 878 ) print ( \"Doe_ID\" , idx + 1 ) reg . compare ( idx * 1000 , ( idx + 1 ) * 1000 ) Doe_ID 806 % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive () interactive(children=(FloatSlider(value=1.1862613636363641, description='Blechdicke', max=1.48, min=0.99, step\u2026 Alternative features # The features previsously chosen lead to a worse performance than the first manual trials... When using Material_ID and Stempel_ID instead of Blechdicke and Ziehspalt, it is satisfying again. from cut_predictor import CutPredictor reg = CutPredictor ( data = data , process_parameters = [ 'Material_ID' , 'Niederhalterkraft' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Material_ID' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'tp' , output = 'deviationc' ) config = { 'batch_size' : 4096 , 'max_epochs' : 50 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 } reg . custom_model ( save_path = 'best_model' , config = config , verbose = True ) reg . training_summary () idx = np . random . choice ( 878 ) reg . compare ( idx * 1000 , ( idx + 1 ) * 1000 ) % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive () interactive(children=(Dropdown(description='Material_ID', options=(1, 2, 3, 4, 5, 6), value=1), FloatSlider(va\u2026","title":"Cut x0"},{"location":"Cut_x0/#x0-cut-prediction","text":"import numpy as np import pandas as pd import matplotlib.pyplot as plt plt . rcParams [ 'figure.dpi' ] = 150","title":"x0 cut prediction"},{"location":"Cut_x0/#loading-the-data","text":"# Load the data using pandas data = pd . read_csv ( '../data/cut_x0.csv' ) data = data . head ( - 1000 ) # remove last experiment data . head ( 10 )","title":"Loading the data"},{"location":"Cut_x0/#creating-the-regressor","text":"from cut_predictor import CutPredictor reg = CutPredictor ( data = data , process_parameters = [ 'Blechdicke' , 'Niederhalterkraft' , 'Ziehspalt' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Ziehspalt' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'tp' , output = 'deviationc' ) # Print a summary of the data reg . data_summary () Data summary ------------------------------------------------------------ Process parameters: - Blechdicke : numerical [ 0.99 ... 1.48 ] - Niederhalterkraft : numerical [ 10.0 ... 500.0 ] - Ziehspalt : categorical [1.6, 2.4] - Einlegeposition : categorical [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5] - Ziehtiefe : categorical [30, 50, 70] Position variable: - tp : numerical, [ 0.0 / 5.0 ] Output variable: - deviationc : numerical, [ -3.16506211149574 / 7.228601057768613 ] Inputs ------------------------------------------------------------ (880000, 19) Outputs ------------------------------------------------------------ (880000,)","title":"Creating the regressor"},{"location":"Cut_x0/#training-methods","text":"","title":"Training methods"},{"location":"Cut_x0/#autotuning","text":"best_config = reg . autotune ( save_path = 'best_x0_model' , trials = 100 , max_epochs = 50 , layers = [ 3 , 5 ], neurons = [ 64 , 256 , 64 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-5 , 1e-3 ] ) reg . training_summary ()","title":"Autotuning"},{"location":"Cut_x0/#alternative-define-a-custom-network-and-do-the-optimization-yourself","text":"One can also run the autotuning for a limited number of epochs and then fine-tune the best configuration by training it longer. config = { 'batch_size' : 4096 , 'max_epochs' : 50 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 } # or best_config from autotune if you already did it once reg . custom_model ( save_path = 'best_x0_model' , config = config , verbose = True ) reg . training_summary () Metal device set to: Apple M1 Pro systemMemory: 16.00 GB maxCacheSize: 5.33 GB Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 128) 2560 dense_1 (Dense) (None, 128) 16512 dense_2 (Dense) (None, 128) 16512 dense_3 (Dense) (None, 128) 16512 dense_4 (Dense) (None, 128) 16512 dense_5 (Dense) (None, 1) 129 ================================================================= Total params: 68,737 Trainable params: 68,737 Non-trainable params: 0 _________________________________________________________________ Epoch 1/50 194/194 [==============================] - 2s 7ms/step - loss: 0.0192 - val_loss: 0.0018 Epoch 2/50 194/194 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013 Epoch 3/50 194/194 [==============================] - 1s 7ms/step - loss: 9.9587e-04 - val_loss: 0.0011 Epoch 4/50 194/194 [==============================] - 1s 7ms/step - loss: 8.5166e-04 - val_loss: 0.0011 Epoch 5/50 194/194 [==============================] - 1s 6ms/step - loss: 7.6869e-04 - val_loss: 9.9730e-04 Epoch 6/50 194/194 [==============================] - 1s 7ms/step - loss: 6.6825e-04 - val_loss: 8.9133e-04 Epoch 7/50 194/194 [==============================] - 1s 7ms/step - loss: 6.2191e-04 - val_loss: 8.3773e-04 Epoch 8/50 194/194 [==============================] - 1s 7ms/step - loss: 5.9185e-04 - val_loss: 9.7526e-04 Epoch 9/50 194/194 [==============================] - 1s 7ms/step - loss: 5.6919e-04 - val_loss: 8.8830e-04 Epoch 10/50 194/194 [==============================] - 1s 7ms/step - loss: 5.1496e-04 - val_loss: 7.7968e-04 Epoch 11/50 194/194 [==============================] - 1s 7ms/step - loss: 4.8956e-04 - val_loss: 7.8011e-04 Epoch 12/50 194/194 [==============================] - 1s 6ms/step - loss: 4.6958e-04 - val_loss: 7.5043e-04 Epoch 13/50 194/194 [==============================] - 1s 7ms/step - loss: 4.4460e-04 - val_loss: 7.7862e-04 Epoch 14/50 194/194 [==============================] - 1s 6ms/step - loss: 4.2258e-04 - val_loss: 8.3322e-04 Epoch 15/50 194/194 [==============================] - 1s 7ms/step - loss: 4.0747e-04 - val_loss: 7.5810e-04 Epoch 16/50 194/194 [==============================] - 1s 7ms/step - loss: 3.9185e-04 - val_loss: 7.2246e-04 Epoch 17/50 194/194 [==============================] - 1s 6ms/step - loss: 3.6418e-04 - val_loss: 7.2556e-04 Epoch 18/50 194/194 [==============================] - 1s 6ms/step - loss: 3.6550e-04 - val_loss: 7.0186e-04 Epoch 19/50 194/194 [==============================] - 1s 7ms/step - loss: 3.5533e-04 - val_loss: 7.8825e-04 Epoch 20/50 194/194 [==============================] - 1s 6ms/step - loss: 3.2706e-04 - val_loss: 8.1836e-04 Epoch 21/50 194/194 [==============================] - 1s 7ms/step - loss: 3.2028e-04 - val_loss: 7.0829e-04 Epoch 22/50 194/194 [==============================] - 1s 7ms/step - loss: 3.1008e-04 - val_loss: 7.9029e-04 Epoch 23/50 194/194 [==============================] - 1s 7ms/step - loss: 3.0182e-04 - val_loss: 6.6371e-04 Epoch 24/50 194/194 [==============================] - 1s 7ms/step - loss: 2.9043e-04 - val_loss: 8.6761e-04 Epoch 25/50 194/194 [==============================] - 1s 7ms/step - loss: 2.8357e-04 - val_loss: 7.1200e-04 Epoch 26/50 194/194 [==============================] - 1s 7ms/step - loss: 2.7604e-04 - val_loss: 6.7895e-04 Epoch 27/50 194/194 [==============================] - 1s 7ms/step - loss: 2.7605e-04 - val_loss: 6.6027e-04 Epoch 28/50 194/194 [==============================] - 1s 7ms/step - loss: 2.6710e-04 - val_loss: 6.5750e-04 Epoch 29/50 194/194 [==============================] - 1s 6ms/step - loss: 2.4262e-04 - val_loss: 6.8879e-04 Epoch 30/50 194/194 [==============================] - 1s 7ms/step - loss: 2.3386e-04 - val_loss: 7.2790e-04 Epoch 31/50 194/194 [==============================] - 1s 6ms/step - loss: 2.2975e-04 - val_loss: 6.2066e-04 Epoch 32/50 194/194 [==============================] - 1s 7ms/step - loss: 2.1958e-04 - val_loss: 6.4486e-04 Epoch 33/50 194/194 [==============================] - 1s 7ms/step - loss: 2.1594e-04 - val_loss: 6.7419e-04 Epoch 34/50 194/194 [==============================] - 1s 6ms/step - loss: 2.1231e-04 - val_loss: 7.2574e-04 Epoch 35/50 194/194 [==============================] - 1s 6ms/step - loss: 1.9914e-04 - val_loss: 6.5656e-04 Epoch 36/50 194/194 [==============================] - 1s 7ms/step - loss: 1.9153e-04 - val_loss: 7.1846e-04 Epoch 37/50 194/194 [==============================] - 1s 7ms/step - loss: 2.0060e-04 - val_loss: 6.6978e-04 Epoch 38/50 194/194 [==============================] - 1s 6ms/step - loss: 1.7992e-04 - val_loss: 6.6546e-04 Epoch 39/50 194/194 [==============================] - 1s 7ms/step - loss: 1.7609e-04 - val_loss: 7.3219e-04 Epoch 40/50 194/194 [==============================] - 1s 7ms/step - loss: 1.7318e-04 - val_loss: 7.1188e-04 Epoch 41/50 194/194 [==============================] - 1s 7ms/step - loss: 1.5796e-04 - val_loss: 6.9973e-04 Epoch 42/50 194/194 [==============================] - 1s 7ms/step - loss: 1.5774e-04 - val_loss: 6.7213e-04 Epoch 43/50 194/194 [==============================] - 1s 7ms/step - loss: 1.4236e-04 - val_loss: 6.9006e-04 Epoch 44/50 194/194 [==============================] - 1s 7ms/step - loss: 1.5219e-04 - val_loss: 6.8170e-04 Epoch 45/50 194/194 [==============================] - 1s 7ms/step - loss: 1.2968e-04 - val_loss: 6.9588e-04 Epoch 46/50 194/194 [==============================] - 1s 7ms/step - loss: 1.3347e-04 - val_loss: 6.7843e-04 Epoch 47/50 194/194 [==============================] - 1s 7ms/step - loss: 1.1999e-04 - val_loss: 6.1209e-04 Epoch 48/50 194/194 [==============================] - 1s 7ms/step - loss: 1.2297e-04 - val_loss: 6.2921e-04 Epoch 49/50 194/194 [==============================] - 1s 7ms/step - loss: 1.4646e-04 - val_loss: 6.1986e-04 Epoch 50/50 194/194 [==============================] - 1s 6ms/step - loss: 1.0288e-04 - val_loss: 6.1435e-04 INFO:tensorflow:Assets written to: best_x0_model/assets Validation mse: 0.0006143474020063877","title":"Alternative: define a custom network and do the optimization yourself"},{"location":"Cut_x0/#other-alternative-the-model-has-already-been-trained","text":"We just need to reload it to make predictions. reg . load ( load_path = 'best_x0_model' ) Metal device set to: Apple M1 Pro systemMemory: 16.00 GB maxCacheSize: 5.33 GB","title":"Other alternative: the model has already been trained"},{"location":"Cut_x0/#visualization","text":"","title":"Visualization"},{"location":"Cut_x0/#prediction-for-single-process-parameter-values","text":"x , y = reg . predict ({ 'Blechdicke' : 1.01 , 'Niederhalterkraft' : 410.0 , 'Ziehspalt' : 2.4 , 'Einlegeposition' : - 5 , 'Ziehtiefe' : 30 }, nb_points = 1000 ) plt . figure () plt . plot ( x , y ) plt . xlabel ( 'tp' ) plt . ylabel ( 'deviationc' ) Text(0, 0.5, 'deviationc')","title":"Prediction for single process parameter values"},{"location":"Cut_x0/#comparison-with-the-ground-truth-on-the-training-set","text":"Randomly choose an id between 0 and 877 and compare the prediction to the ground truth. idx = np . random . choice ( 878 ) print ( \"Doe_ID\" , idx + 1 ) reg . compare ( idx * 1000 , ( idx + 1 ) * 1000 ) Doe_ID 806 % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive () interactive(children=(FloatSlider(value=1.1862613636363641, description='Blechdicke', max=1.48, min=0.99, step\u2026","title":"Comparison with the ground truth on the training set"},{"location":"Cut_x0/#alternative-features","text":"The features previsously chosen lead to a worse performance than the first manual trials... When using Material_ID and Stempel_ID instead of Blechdicke and Ziehspalt, it is satisfying again. from cut_predictor import CutPredictor reg = CutPredictor ( data = data , process_parameters = [ 'Material_ID' , 'Niederhalterkraft' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Material_ID' , 'Stempel_ID' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'tp' , output = 'deviationc' ) config = { 'batch_size' : 4096 , 'max_epochs' : 50 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 } reg . custom_model ( save_path = 'best_model' , config = config , verbose = True ) reg . training_summary () idx = np . random . choice ( 878 ) reg . compare ( idx * 1000 , ( idx + 1 ) * 1000 ) % matplotlib inline plt . rcParams [ 'figure.dpi' ] = 150 reg . interactive () interactive(children=(Dropdown(description='Material_ID', options=(1, 2, 3, 4, 5, 6), value=1), FloatSlider(va\u2026","title":"Alternative features"},{"location":"datapreparation/","text":"Data preparation # The data should be passed to the CutPredictor as a pandas Dataframe. Each experiment (or simulation) consists of: a set of \\(d\\) process parameters defining the experiment (definition of the material, force applied, etc). a 1D position regularly sampled along some axis ( \\(m\\) points). a resulting deviation (or anything else) for each position. The goal is to learn to predict the deviation for any position, given a set of (new) process parameters. Taking the example of the x0 cut in the Cut_x0.ipynb notebook, the process parameters are: Blechdicke Niederhalterkraft Ziehspalt Einlegeposition Ziehtiefe the position is tp and the value to predict is deviationc . The data frame should have \\(d+2\\) named columns, the \\(d\\) process parameters, the position and the output deviation. Each row should have the value of all attributes for a single point: Blechdicke Kraft Ziehspalt Position Ziehtiefe tp deviationc 1.01 410.0 2.4 -5 30 0.0 3.56 1.01 410.0 2.4 -5 30 0.01 3.57 1.01 410.0 2.4 -5 30 0.02 3.58 ... ... ... ... ... ... ... This means that the process parameters are repeated \\(m\\) times, which is a waste of disk space. However, this will have to be dome at some points before feeding the data to the neural network, so it is better to waste disk space than computing time. Once the data is prepared in that format and saved to disk (csv, hdf5...), the data frame can be loaded: data = pd . read_csv ( 'data.csv' )","title":"Data preparation"},{"location":"datapreparation/#data-preparation","text":"The data should be passed to the CutPredictor as a pandas Dataframe. Each experiment (or simulation) consists of: a set of \\(d\\) process parameters defining the experiment (definition of the material, force applied, etc). a 1D position regularly sampled along some axis ( \\(m\\) points). a resulting deviation (or anything else) for each position. The goal is to learn to predict the deviation for any position, given a set of (new) process parameters. Taking the example of the x0 cut in the Cut_x0.ipynb notebook, the process parameters are: Blechdicke Niederhalterkraft Ziehspalt Einlegeposition Ziehtiefe the position is tp and the value to predict is deviationc . The data frame should have \\(d+2\\) named columns, the \\(d\\) process parameters, the position and the output deviation. Each row should have the value of all attributes for a single point: Blechdicke Kraft Ziehspalt Position Ziehtiefe tp deviationc 1.01 410.0 2.4 -5 30 0.0 3.56 1.01 410.0 2.4 -5 30 0.01 3.57 1.01 410.0 2.4 -5 30 0.02 3.58 ... ... ... ... ... ... ... This means that the process parameters are repeated \\(m\\) times, which is a waste of disk space. However, this will have to be dome at some points before feeding the data to the neural network, so it is better to waste disk space than computing time. Once the data is prepared in that format and saved to disk (csv, hdf5...), the data frame can be loaded: data = pd . read_csv ( 'data.csv' )","title":"Data preparation"},{"location":"usage/","text":"Usage # Loading the data # Once the data is loaded as a pandas Dataframe, it can be passed to the CutPredictor object: reg = CutPredictor ( data = data , process_parameters = [ 'Blechdicke' , 'Niederhalterkraft' , 'Ziehspalt' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Ziehspalt' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'tp' , output = 'deviationc' ) One has to specify among all the columns present in the frame which ones are process parameters, which one is the input position and which one is the output. Optionally, one can specify which process parameter is categorical (as opposed to numerical), i.e. takes discrete values. This only influences the training of the neural network, as categorical attributes are then one-hot encoded before being passed to the NN. This is however optional. When the data is loaded in the CutPredictor , it is normalized to allow for efricient training, so this can take a while depending on the size of your data. Training the network # CutPredictor uses a feedforward neural network to perform the regression. It is a simple multi-layer perceptron with several layers of neuron, using the mean square error as a loss function. The hyperparameters of the NN are: the number of layers and neurons. the learning rate. the dropout level for regularization. the batch size. the number of epochs It may be tricky to find the right hyperparameters for your data. Two methods are available: an automatic one using the optuna library and a manual one. Autotuning # The autotune method launches a Bayesian optimization procedure thanks to the optuna library to find the best set of hyperparameters for the data. In a nutshell, it will train trials=100 different networks with hyperparameters sampled ffrom the specified ranges: best_config = reg . autotune ( save_path = 'best_model' , trials = 100 , max_epochs = 50 , layers = [ 3 , 5 ], neurons = [ 64 , 256 , 64 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-5 , 1e-3 ] ) The networks have diffrent number of layers, neurons per layer, learning rates and so on. The network with the best validation accuracy is finally selected and saved in the best_model/ directory. It can be used to make predictions. The more trials you make, the more likely you will find a satisfying solution if the provided ranges are well chosen. But if the ranges are too wide, you will neeed many trials to find the optimal setup. The autotuning procedure can take a while depending on the number of trials, the size of the networks and the maximum number of epochs. If you have multiple GPUs on the system, try to limit tensorflow training to one of them (e.g. GPU of id 0). If your code is in a script, use: CUDA_VIDIBLE_DEVICES = 0 python Script . py In a notebook, run that cell first: import os os . environ [ \"CUDA_DEVICE_ORDER\" ] = \"PCI_BUS_ID\" os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"0\" Manual selection # If you prefer to do the optimization yourself, or fine-tune the architecture found by autotune by training it for more epochs, you can define the network using a dictionary: config = { 'batch_size' : 4096 , 'max_epochs' : 50 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 } and train that model: reg . custom_model ( save_path = 'best_model' , config = config , verbose = True ) The model's weights are saved in best_model/ . If you already have trained a model and only want to visualize the results, you can simply load it: reg . load ( load_path = 'best_model' ) Visualizing the results # To make a prediction for a (potentially new) set of process parameters, simply pass them to the predict() method as a dictionary: x , y = reg . predict ({ 'Blechdicke' : 1.01 , 'Niederhalterkraft' : 410.0 , 'Ziehspalt' : 2.4 , 'Einlegeposition' : - 5 , 'Ziehtiefe' : 30 }, nb_points = 1000 ) This will return 1000 values of the position x as well as the corresponding predicted output y . In a Jupyter notebook, you can use the interactive() method to get sliders for the process parameters and interactively visualize the predictions: % matplotlib inline # necessary plt . rcParams [ 'figure.dpi' ] = 150 # bigger figures reg . interactive ()","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#loading-the-data","text":"Once the data is loaded as a pandas Dataframe, it can be passed to the CutPredictor object: reg = CutPredictor ( data = data , process_parameters = [ 'Blechdicke' , 'Niederhalterkraft' , 'Ziehspalt' , 'Einlegeposition' , 'Ziehtiefe' ], categorical = [ 'Ziehspalt' , 'Einlegeposition' , 'Ziehtiefe' ], position = 'tp' , output = 'deviationc' ) One has to specify among all the columns present in the frame which ones are process parameters, which one is the input position and which one is the output. Optionally, one can specify which process parameter is categorical (as opposed to numerical), i.e. takes discrete values. This only influences the training of the neural network, as categorical attributes are then one-hot encoded before being passed to the NN. This is however optional. When the data is loaded in the CutPredictor , it is normalized to allow for efricient training, so this can take a while depending on the size of your data.","title":"Loading the data"},{"location":"usage/#training-the-network","text":"CutPredictor uses a feedforward neural network to perform the regression. It is a simple multi-layer perceptron with several layers of neuron, using the mean square error as a loss function. The hyperparameters of the NN are: the number of layers and neurons. the learning rate. the dropout level for regularization. the batch size. the number of epochs It may be tricky to find the right hyperparameters for your data. Two methods are available: an automatic one using the optuna library and a manual one.","title":"Training the network"},{"location":"usage/#autotuning","text":"The autotune method launches a Bayesian optimization procedure thanks to the optuna library to find the best set of hyperparameters for the data. In a nutshell, it will train trials=100 different networks with hyperparameters sampled ffrom the specified ranges: best_config = reg . autotune ( save_path = 'best_model' , trials = 100 , max_epochs = 50 , layers = [ 3 , 5 ], neurons = [ 64 , 256 , 64 ], dropout = [ 0.0 , 0.5 , 0.1 ], learning_rate = [ 1e-5 , 1e-3 ] ) The networks have diffrent number of layers, neurons per layer, learning rates and so on. The network with the best validation accuracy is finally selected and saved in the best_model/ directory. It can be used to make predictions. The more trials you make, the more likely you will find a satisfying solution if the provided ranges are well chosen. But if the ranges are too wide, you will neeed many trials to find the optimal setup. The autotuning procedure can take a while depending on the number of trials, the size of the networks and the maximum number of epochs. If you have multiple GPUs on the system, try to limit tensorflow training to one of them (e.g. GPU of id 0). If your code is in a script, use: CUDA_VIDIBLE_DEVICES = 0 python Script . py In a notebook, run that cell first: import os os . environ [ \"CUDA_DEVICE_ORDER\" ] = \"PCI_BUS_ID\" os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"0\"","title":"Autotuning"},{"location":"usage/#manual-selection","text":"If you prefer to do the optimization yourself, or fine-tune the architecture found by autotune by training it for more epochs, you can define the network using a dictionary: config = { 'batch_size' : 4096 , 'max_epochs' : 50 , 'layers' : [ 128 , 128 , 128 , 128 , 128 ], 'dropout' : 0.0 , 'learning_rate' : 0.005 } and train that model: reg . custom_model ( save_path = 'best_model' , config = config , verbose = True ) The model's weights are saved in best_model/ . If you already have trained a model and only want to visualize the results, you can simply load it: reg . load ( load_path = 'best_model' )","title":"Manual selection"},{"location":"usage/#visualizing-the-results","text":"To make a prediction for a (potentially new) set of process parameters, simply pass them to the predict() method as a dictionary: x , y = reg . predict ({ 'Blechdicke' : 1.01 , 'Niederhalterkraft' : 410.0 , 'Ziehspalt' : 2.4 , 'Einlegeposition' : - 5 , 'Ziehtiefe' : 30 }, nb_points = 1000 ) This will return 1000 values of the position x as well as the corresponding predicted output y . In a Jupyter notebook, you can use the interactive() method to get sliders for the process parameters and interactively visualize the predictions: % matplotlib inline # necessary plt . rcParams [ 'figure.dpi' ] = 150 # bigger figures reg . interactive ()","title":"Visualizing the results"}]}